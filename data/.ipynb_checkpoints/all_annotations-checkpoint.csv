paper,contexts:with_interactions,contexts:without_interactions,contexts:content_analysis,contexts:writing,contexts:training_data,contexts:advice,LLMs studied,link,year_noarxiv,eval_open,eval_closed,eval_other,demo_across,demo_within,prompting,RAG,Fine-tuning,Pretraining,RLHF,Other,target_pop,input,object,default,gender,race,nationality,location,immigration,age,education,political,disability,religion,class,sexuality,other,Conclusion on Representativeness?
Argyle et al.,,1,,,,,GPT-3,,,1,1,,1,,1,,,,,,American Population,1,1,,"male, female ","Whites, Blacks, Hispanics ",,state of residence,,"18-30, 31-45, 46-60, 60+",,"Conservatives, Moderates, Liberals",,1,,,,yes
Aher et al.,1 (Ultimatum Game),1 (Milgram Shock Experiment),1 (Garden-path),,,1 (Wisdom of crowds),"text-ada-001, text-babbage-001, text-curie-001,
text-davinci-001, text-davinci-002, text-davinci-003, gpt-
35-turbo, gpt-4",,,1,1,,1,,"1 (k-choice prompts, improving prompts based on output)",,,,,,implicit / surnames obtained from American census,1,1,,"gender (Mr. and Mrs.), wisdom : Mx. ",via Name: racially diverse names (American Indian and Alaska Native; Asian and Native Hawaiian & other pacific islander; Black or African American; Hispanic or Latino; White),,,,,,,,,,,,partial (hyperaccuracy bias)
Gerosa et al.,1 (multi-persona),1 (mega-persona? statistical approach),,,,,GPT-4,,,1,,,1,,1 (prompting and prompt engineering),,,,,,software engineering community ,1 (survey and focus group),1 (participants in focus group),,"Mary vs. John ; man, woman, non-binary, not say, self describe",,,"live in North-America, South America, Europe, Africa, Asia, Australia",,"24 or less, 25-34, 35-44, 55-64, over 64",,,,,"paid, unpaid, mostly paid, mostly unpaid",,,"yes, closely mimic human generated-content"
Park et al.,1,,,,,,GPT-3,,,1,,,,,1,,,,,,not specified,1,1,,implicitly: name,implicitly: name,,via Subreddit,,,"implicitly: occupation, student, PhD (via description)","implicitly: comments shared (not encouraging suicide, not anti-therapy",,,,,occupation,"yes, study participants were only slightly better than random guessing when distinguishing SimReddit and real world"
FairPair: A Robust Evaluation of Biases in Language Models through Paired Perturbations,,1,,1,,,"gpt-2, gpt-2 xl, Tk-instruct, gpt-j, llama-13b, instruct-gpt, gpt-turbo-3.5 (to perform pertubations)",http://arxiv.org/abs/2404.06619v1,,1,,,,1,1,,,,,pertubation method --> own FairPair framework: constructing multiple paired continuations ,not specified,,1,1,John vs. Jane; man vs. woman,,,,,,,,,,,,,
"Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion Related to Harms of Misinformation",,1,1,,,,gpt-3.5-turbo,http://arxiv.org/abs/2401.16558v1,,,1,,,1,1,,,,,,not specified,1,,1,man vs. woman,,,,,,,,,,,,,"no, amplification found in RQ1 and biased towards outputs generated by men in RQ2"
Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset,,,,,,1,"gpt-2, pythia 2.8B, OPT 2.7B",http://arxiv.org/abs/2411.08243v1,,1,1,,1,1,,,,1,,using the HH dataset,not specified,,1,1,diverse,US (div),1,,,1,,,,1,,1,,"no, can lead to disparate exaggerated safety
behaviors across demographic groups"
"Focus On This, Not That! Steering LLMs With Adaptive Feature Specification",,,,,,1,"Llama-3.1-8B-Instruct, Mistral-7B-Instruct-v0.3, Vicuna-13B-v1.5",http://arxiv.org/abs/2410.22944v1,,1,1,"extrinsic evaluation of fine-tuned model (downstream tasks like sentiment analysis, question answering etc.)",,,,,1,,,focus instruction-tuning (introduced framework),not specified,,1,1,man vs. woman,1,,,,"more youthful, old ",,,1,,,,,"yes, the bias mitigation works "
HumBEL: A Human-in-the-Loop Approach for Evaluating Demographic Factors of Language Models in Human-Machine Conversations,,,1,1,,,"text-davinci-002, gpt-3.5-turbo-0301, Llama-2-chat 7B, Zephyr-Î²7B , Mistral 7B v0.2, InstructGPT, ChatGPT (0301), ChatGPT (1106)",http://arxiv.org/abs/2305.14195v3,,1,,"Human in the loop clinical examinations; 1) analyzed by experts, 2) automatically evaluated",,1,1,,,,,,,,1,1,,,,,,age in years (5-21 years old),,,,,,,,
Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models,,,,1,,,"GPT-3.5, GPT-4",http://arxiv.org/abs/2305.18189v1,,1,,,1,1,1,,,,,,"implicit / ""American sterotypes"" in limitations",1,1,1,"man, woman, non-binary","Asian, Black, La-
tine, Middle-Eastern (ME), and White",,,,,,,,,,,,no
CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations,1,1,,,,,gpt-4 models,http://arxiv.org/abs/2310.11501v1,,1,,closed evaluation shortly mentioned with multiple choice setting but not explicitly performed,1,1,1,,,,,,not specified; implicitely: amercian (looking at race description),1,1,1,"man, woman, non-binary","white, black, hispanic, middle-eastern, asian",,,,"20, 40 and 80 years old",,"moderate, conservative, liberal",,,,,,partial; asian and woman are not significantly prone to caricatures; the rest is
ChatGPT vs Social Surveys: Probing the Objective and Subjective Human Society,,1,,,,,chatgpt-3.5,http://arxiv.org/abs/2409.02601v1,,,1,study 1: clear composition of possible demographics; study 2: scale 1-10 respectively strongly agree - strongly disagree,1,1,1,,,,,parameter adjustment,2020 US population,1,1,1,"male, female","Asian, Black or African American, Hispanic or Latino, White, Others",,"rural, urban",,in years,"Less than 9th grade, 9th to 12th grade, High School Graduate, Some College no degree, Associate's Degree, Bachelor's Degree, Graduate or Professional Degree",,,,"<10,000, 10,000-14,999, 15,000-24,999, 25,000 - 34,999, 35,000 - 49,999, 50,000 - 74,999, 75,000 - 99,999, 100,000 - 149,999, 150,000 - 199,999, >200,000",,,"partial; ""Our findings reveal instances of commendable simulation alignment with
the actual US 2020 population, alongside evident biases when compared to the real population, as well as
significant deviations from human self-reported responses to the aforementioned attitudinal inquiries."""
Prompt and Prejudice,,,1,,,1,"Llama3-8B, Qwen-7B and Mistral 7B;  llava-1.6-7b",http://arxiv.org/abs/2408.04671v1,,,1,,1,1,1,,,,,,governmental data (US),,1,1,via name,"via name (implicit categories: African, African-American, Anglo, Arab, Asian, European, and Hispanic)",,,,,,,,,,,,
GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy,,,,,,1,"ChatGPT3.5 and ChatGPT4o (OpenAI), Claude2.1 and
Claude-3-sonnet (Anthropic), and Coral and Coral R+ (Co-
here)",http://arxiv.org/abs/2407.18008v1,,,1,,,,1,,,,,temperature and top-p set to 1,"German parliamentarians from major parties (SPD, Greens, AfD, Left, FDP, CDU-
CSU alliance)",1,1,1,"male, female",,,,,year of birth,degree / what they studied,party affiliation,,,,,name of parliamentarian,
IndiBias: A Benchmark Dataset to Measure Social Biases in Language Models for Indian Context,,,,1 (inspecting biases),"1 (to generate dataset with stereotypes; labeled by annotators as stereo, anti-stereo)",,"chat/gpt-3.5-turbo, complete/text-davinci-003 (for training data) XLMR, IndicBert, Muril, Bernice, mT5, mBART, Bloom, mGPT, Llama-v2, Mistral (under inspection)",http://arxiv.org/abs/2403.20147v2,,,,via masking: two sentences in training data with stereo and antistereo (like CrowS; substituting male indicators with female for example) evaluation: look at probabilities of modified words (e.g. him-->her) given unmodified words (context words),1,1,1,,,,,,Indian population,,1,1,"female, male",,,,,"kid, young, middle-aged, old, senior citizen",,,handicapped/ not mentioned,"buddhist, christian, hindu, jain, muslim, sikh",,,"caste, occupation, physical appearance",
Will Trump Win in 2024? Predicting the US Presidential Election via Multi-step Reasoning with Large Language Models,,1,,,,1,GPT-4o for election predictions,http://arxiv.org/abs/2411.03321v1,,,1,,,,1,,,,,,"Sync synthetic data generation framework (Li et al., 2020b), which probabilistically reconstructs individual-level demographic and behavioral profiles from aggregated public datasets (american voters) + ANES (sample of US population)",1,1 (candidate's background),,"male, female (not specified in non-binary was used)","White mentioned, specified as : resident of the [] ethnicity",,state of residence,,in ranges of 4 years,education level mentioned,[conservative-liberal spectrum]. (in one iteration),,,"marital status, family income in ranges (indicated as steps of 25,000); individual income",,household size; presence of children; occupation;,"partial, for 2020:  In these polarized states, the predictions closely mirrored the actual voting outcomes; For swing and tipping-point states [...] chieved robust results, correctly predicting the outcomes in 9 out of 11 states; for 2024: mispredicted"
KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Application,,,,1,,,"HyperCLOVA (82B),
HyperCLOVA (30B), and GPT-3.",http://arxiv.org/abs/2305.17701v2,,1,,"classifier trained on KoSBi data (generated contexts and sentences w.r.t denmographics labeled as ""safe"" and ""unsafe"" by crowdworkers)",1,,1 (demonstration based prompting to create KoSBI dataset),,,,,"rejection sampling (filtering-based moderation approach, Ganguli et al.)",Korean,,1,1,"male, female, others","race, ethnicity & nationality as one category (south korean, north korean, chinese, japanese, American (U.S.), Russian, Asian, African, European, AMericans (Oceanians), People of Color, White)",,domestic area of origin ,,"age & GENERATION (baby, children, teenagers, young people, middle-aged, old-people, baby boomers, 386 generation, generation X, Millennials, Generation Z, Alpha Generation)","academic background, universities, major","liberal, conservative, other",disability,"non-reliogious, protestantism, buddhism, catholic, islam, others","employment type, economic condition, occupoation",homosexual,"physical appearance, marital status, family form, pregnancy & birth, criminal record","partial, unsafe generations decreases for all models by 16.47% on average"
Does RAG Introduce Unfairness in LLMs? Evaluating Fairness in Retrieval-Augmented Generation Systems,,,,,,1,"retrievers: BM25 (sparse), E5-base-v2, E5-large-v2 (dense); generators: Meta-Llama-3-8B-Instruct, Meta-Llama-3-70B-Instruct",http://arxiv.org/abs/2409.19804v1,,,1,,1,1,,1,,,,,not specified,,1,1,"male, female",,,1,,,,,,,,,,"partial, bias can be mitigated by adjusting question formats or increasing number of retrieved documents and prioritizig relevant documents"
"Sensitivity, Performance, Robustness: Deconstructing the Effect of Sociodemographic Prompting",,,1,,,,"InstructGPT(175B), Flan-T5(80M). Flan-T5(250M), Flan-T5(780M), Flan-T5(3B), Flan-T5(11B), Flan-UL(20B). Tk-Instruct(80M), Tk-Instruct(250M), Tk-Instruct(780M), Tk-Instruct(3B), Tk-Instruct (11B), OPT-IML(1.3B), OPT-IML(30B), Dolly-V2(2.8B), Dolly-V2(6.9B), Dolly-V2(12B)",http://arxiv.org/abs/2309.07034v2,,,1,,1,1,1,,,,,,implicitly American,1,,1,"male, female, non-binary","White, Black or African American, Asian, Hispanic, Native Hawaiian or Pacific Islander, American Indian or Alaska Native",,,,"Under 18, 18-24, 25-34, 35-44. 45-54, 55-64, 65 or older","less than high school degree, high school graduate, some college but no degree, associate degree in college, bachelors degree in college, masters degree, professional degree, doctoral degree","liberal, conservative, independent",,,,,,"partial, Sociodemographic prompting can improve zero-shot performance; however, they conclude that mostly prompt formulation specifically indluences prediction outcomes"
"Quite Good, but Not Enough: Nationality Bias in Large Language Models -- A Case Study of ChatGPT",,,,1,,,"chatGPT, gpt-2, bert-base-chinese, chinese-bert-wwm-ext, chinese-roberta-wwm-ext, chinese-roberta-wwm-ext-large",http://arxiv.org/abs/2405.06996v1,,1,,sentiment using RoBERTa; metrics for chinese prompts and english prompts are directly compared; scoring by experrs and by chatGPT,,1,1,,,,,4 different temperature settings,chinese and english prompts,,1,1,,,193 member states of United Nations and 2 non-member states as observers (Vatican and Palestine),,,,,,,,,,,no
Mitigating the Risk of Health Inequity Exacerbated by Large Language Models,,,,,,1,"GPT-4, GPT-4o Mini, Gemini, Claude (Claude-3-5-sonnet-20240620) (general evaluation w.r.t. metrics) LLaMA3 8B, Mistral v0.3 (w/ EquityGuard)",http://arxiv.org/abs/2410.05180v2,,,1,equal opportunity (EO) and demographic parity (DP); NDCG@10; ,1,1,,,,,,Contrastive Learning (EquityGuard Framework),,,1,1,"male, female","white, black, hispanic, asian, native-american, pacific islander, mixed race, middle-eastern, indigenous, african-american, south-asian, east-asian",,,,,illiterate,,disabled,,"unemployed, low-income, homeless",LGBT+,,"yes, Models with EquityGuard pro-
vided more consistent NDCG@10 scores and lower error rates across all SDOH
categories, indicating reduced inequity; Enhanced EO and DP scores affirm that Equity-
Guard promotes equitable model behavior, ensuring that sensitive demographic
factors do not disproportionately influence predictions."
The Woman Worked as a Babysitter: On Biases in Language Generation,,,,1,,,"GPT-2, Google's LLM",http://arxiv.org/abs/1909.01326v2,,1,,,,,1,,,,,,,,1,1,"female, male","Black, White",,,,,,,,,,gay straight,occupation,"no, the LLMs are biased"
All Should Be Equal in the Eyes of Language Models: Counterfactually Aware Fair Text Generation,,,,1,,,"GPT-2 small, GPT-2 large, Pythia",http://arxiv.org/abs/2311.05451v1,,1,,evaluating against ant-stereotype datasets (such as CrowS); human evaluation ,1,1,1,,,,,temperature adjustment (only discussed in a figure),,,1,1,"woman, man","African, Black, White, ...",,,,,,,,"christianity, islam, jewish ...",,,occupation,"yes, ""Our results on three benchmark datasets show that
CAFIE consistently improves the fairness of text generation"""
LIDAO: Towards Limited Interventions for Debiasing (Large) Language Models,,,,1,,,"GPT-2 Large, OPT, Falcon-7B-Instruct, ",http://arxiv.org/abs/2406.00548v1,,1,1,intrinsic evaluation: perplexity; human evaluation for fluency and friendliness,,,1,,1,,,"LIDAO: own framework to improve debias-flunecy trade-off by (1)Minimizing mutual information between global properties and demographic groups, (2) Applying limited interventions only when necessary, rather than constant constraints and (3) Extending the approach to handle adversarial prompts in large language models",,,1,1,"male, female",,,,,,,,,,,,,"partial, LIDAO demonstrates a better fairness-fluency trade-off compared to existing methods by applying limited interventions only when necessary, rather than constant constraints; however: it does not completely eliminate bias without affecting fluency"
ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context,,,,,,1,GPT-3.5 for persona generation and guardrail evaluation (GPT-4 for request generation to sample from),http://arxiv.org/abs/2407.06866v2,,1,1,,1,1,1,,,,,,American Population,,1,1,"woman, man","Black or African American, Hispanic or Latino, Asian American, White",,,,"13-17, 35-44, 55-64",,"liberal, conservative",,,,,sports fandom (all teams in the NFL),"no, likelihood of a refusal
can be influenced by demographic categories, political affiliation, and even seemingly innocuous
information like sports fandom"
"""I'm sorry to hear that"": Finding New Biases in Language Models with a Holistic Descriptor Dataset",,,,,,1,"GPT-2, DialoGPT, BlenderBot 2.0",http://arxiv.org/abs/2205.09209v2,,1,,"intrinsic evaluation: perplexity; open: classify generations (""style"") and automated classification ",1,1,1,,,,,,,,1,1,1,1,1,1,,1,1,1,1,1,1,,"body type, characteristics, cultural, ","yes, Bias reduction tuning reduces Full Gen Bias by
13% on DialoGPT and 24% on BlenderBot 2.0 3B"
Benchmarking Distributional Alignment of Large Language Models,,1,,,,,"Anthropic Opus, GPT-4, Llama 3 70B, Anthropic Haiku, GPT-3.5 turbo",http://arxiv.org/abs/2411.05403v1,,,1,,,1,1,,,,,,US population,,1,1,,,,,,,,"democrat, republican",,,,,,"partial, study finds that verbalizing distributions (e.g., outputting probabilities in JSON format) achieves better alignment than generating samples or looking at model log-probabilities"
Annotation alignment: Comparing LLM and human annotations of conversational safety,,,1,,,,"GPT-3.5, GPT-4, GPT-4o, Gemini 1.5 Pro, and Llama 3.1 405B Instruct",http://arxiv.org/abs/2406.06369v4,,,1,,1,1,,,,,,,US population,,1,1,"male, female","white, black, multiracial, asian, latinx",,,,,,,,,,,,"partial, GPT-4 does not align significantly more or less with different race-gender groups. dataset too small to resolve significant results; substantial idiosyncratic variation in alignmet within demographic groups"
Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context,,,,,,,"ChatGPT-4.0-Turbo,
Claude-3-Opus, and Gemini-1.0-pro",http://arxiv.org/abs/2406.05972v2,,,1,,1,1,1,,,,,,world bank dataset,1,,,"male, female","African, Hispanic, Asian, Caucasian",,"rural, urban",,"15-24, 25-34, 35-44, 45-54, 55-64, 65+","below lower secondary, lower secondary, upper secondary, short-cycle tertiary, bachelor degree, graduate degrees","lifelong democrat, lifelong republican, barack obama supporter, donald trump supporter","physically disabled, able-bodied","jewish, christian, atheist, religious ",,,marital status,"partial, The incorpora-
tion of socio-demographic features into our analysis revealed significant impacts of human-related
features on the LLM decision-making process, underscoring the potential biases and variability in
their outputs."
Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias,,,,,,1,"Llama-2-7B, Llama-3-8B, Mistral-7B, Gemma-7B, Gemma-2-9B",http://arxiv.org/abs/2212.10678v3,,1,1,,,,1,,,,,,not specified,,1,1,diverse,,,,,,,,,,,,occupation,"no, we observe that these mod-
els show strong stereotypical associations between
gender and stereotypically gendered jobs & Base Models Only Recognize Binary
Genders"
A Matter of Style? Socio-Cultural Differences in Argumentation,,,,,,1,Mistral-7B-v0.1,https://aclanthology.org/2024.argmining-1.18,results for gen. model only found in appendix,1,,qualitative inspection of generated text,,,,,,,,,"German, Italian, and
French (dataset)",,1,,binary,,,residence,,1,,"political spectrum, stance and topics one is interested in",,denomination,,,,
Fairness in Automated Essay Scoring: A Comparative Analysis of Algorithms on German Learner Essays from Secondary Education,,,1,,,,GPT-4,https://aclanthology.org/2024.bea-1.18,,1,,,1,,1,,,,,,German students,,1,1,diverse,,,,,,"grade level (9-12), school",,,,,,"nativeness, cognitive ability (KFT)","partial, when models are trained on entire data, the models show no unfair behavior towards specific subgroups ; training only on subset (on either low, high, or mixed cognitive abilities), the model is unfair to groups not included in training data"
Intersectional Stereotypes in Large Language Models: Dataset and Analysis,,,,,,1,"GPT-3, ChatGPT",https://aclanthology.org/2023.findings-emnlp.575,,,1,,1,1,1,,,,,,not specified,1,,,binary,"black, white, asian",,,,"young, old",,"conservative, progressive","with disability, without disability","non-religious, christian, muslim",,,,"no,  findings revealed that all the models studied
produced stereotypical responses to certain inter-
sectional groups"
MultiPICo: Multilingual Perspectivist Irony Corpus,,,1,,,,"pt-3.5-turbo, PolyLM, mT0",https://aclanthology.org/2024.acl-long.849,,,1,,1,1,1,,,,,,non US (multilingual),1,1,1,binary,,1,,,"Generation: Boomer, Gen X, Gen Y, Gen Z; old, young","student: no, yes",,,,"employed: no, yes",,,yes
LLM Roleplay: Simulating Human-Chatbot Interaction,,1,,,,,"llama-2-13B-Chat, Mixtral-8x7B-Instruct-v0.1, vicuna-13b-v1.5-16k, GPT-4",http://arxiv.org/abs/2407.03974v2,arxiv 2 starts here,1,,,,,1,,,,,,not specified,1,,,binary,Asian or Pacific Islander vs. white,,,,"1, in intervals","doctoral degree, masters degree",,,,,,native english speaking,"yes, Our find-
ings highlight the potential of LLMs in simulating
human-chatbot interactions to synthesize realistic
dialogues"
Bias patterns in the application of LLMs for clinical decision support: A comprehensive study,,,,,,1,"Gemma, Mixtral, LLaMa-2, GPT-4, PaLM-2, Galactica, Palmyra-Med, Meditron",http://arxiv.org/abs/2404.15149v1,,,1,,1,1,1,,,,,,implicitly US,,1,,binary,"White, Black, Hispanic, Asian",,,,,,,,,,,,"partial, While LLMs present a powerful tool for
enhancing clinical decision-making, their potential is contingent upon mitigating inherent
biases. By embracing bias mitigation techniques, fostering inclusive training data, priori-
tizing interpretability, and establishing robust regulatory frameworks and guardrails, the
community can ensure a more responsible and equitable deployment of LLMs in healthcare."
Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias,,1,,,,,"gpt-3.5, gpt-4",http://arxiv.org/abs/2311.00217v2,,,1,,1,,1,,,,,,explicitly US,1,,,binary,"white/non-hispanic, black/non-hispanic, other/non-hispanic, hispanic, 2+ races, ",,,,"â18-29,â â30-44,â â45-59,â and â66+.â","less than high school, high school, some college, bachelor's degree or higher, ","very liberal, somewhat liberal, moderate, somewhat conservative, very conservative; democrat, republican, independent, other, not interested in politics ",,,,,covariates (opinions/ psychological factors),"partial, The overarching findings indicate that GPT-4 accurately predicted voting behaviors and
belief that global warming is happening among diverse sub-populations. However, certain sub-
populations were less accurate"
Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs,,,,,,1,"gpt-3.5, gpt-4-turbo, llama-2-70b",http://arxiv.org/abs/2311.04892v2,,1,1,,1,1,1,,,,,,implicitly US,1,,1,"man, woman, trans man, trans woman, non-binary","African, Hispanic, Asian, Caucasian",,,,,,"lifelong democrat, lifelong republican, obama supporter, trump supporter","physically-disabled, able-bodied","Jewish, Christian, Atheist, Religious",,,,no
Large Language Models Can Infer Psychological Dispositions of Social Media Users,,,,,,1,"gpt-3.5, gpt-4",http://arxiv.org/abs/2309.08631v2,,,1,,1,1,1,,,,,,not specified,,1,1,binary,,,,,"young, old",,,,,,,,"yes, Our findings suggest that LLMs, such as ChatGPT, can infer psychological dispositions from peopleâs social
media posts without having been explicitly trained to do so."
Assessing LLMs for Moral Value Pluralism,,,,,,1,text-davinci-003,http://arxiv.org/abs/2312.10075v1,,1,,,1,1,1,,,,,,global,1,,,binary,,"german, japanese, czech, american, romanian, vietnamese, venezuelan, nigerian",,,"20, 30, 40, 50, 60, 75",,,,,,,,"no, LLM inable to accurately capture moral
perspectives of demographics in non-Western nations"
Large Language Model-based Role-Playing for Personalized Medical Jargon Extraction,,,1,,,1,"gpt-3.5-turbo, gpt-4",http://arxiv.org/abs/2408.05555v1,,,1,,1,1,1,,,,,,not specified,1,,1,binary,,,,,"18-24, 25-34, 35-44, 45-54, 55-64, 65+","<=HS, BA, MA",,,,,,health literacy,yes
STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions,,,,,,1,"gpt-3.5, gpt-4, gemma, mistral, mixtral, llama2-7b, llama2-13b, llama2-70b, llama3-8b, llama3-70b",http://arxiv.org/abs/2409.13843v1,,,1,,1,1,1,,1,,,,implicitly US,,1,,"Male, female, transgender, non-binary, genderqueer","Asian, African, European, Latin and Hispanic, Middle Eastern and North African, Indigenous, Pacific Islander",,,,"child, adolescent, adult, elder",,"liberal, socialist, communist, conservative, capitalist, fascist, nationalist, anarchist","physical, neurological, intellectual ","Judaism, Christianity, Islam, Hinduism, Buddhism, Sikhism, Atheism","Upper, Middle, Working, Lower","Heterosexual, Homosexual, Bisexual, Queer",weight,"partial,  Our findings reveal substantial variability in bias sensitivity across models, with no model consistently identifying bias across all scenarios or achieving over 70% accuracy. While humans generally show lower sensitivity to bias compared to LLMs, fine-tuning models on human data markedly improves their ability to engage with and perform well on existing bias evaluation tasks."
CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias,,,,,,1,"llama-2, Bloom, OPT, Falcon, T0, GPT-Neo",http://arxiv.org/abs/2308.12539v3,,,1,,,1,1,,,,,,names from US Social Security dataset --> explicitly US?,,1,,"names (female, male, gender-neutral)","names (Caucasian, African American, Hispanic, Asian)",,,,,,,,,,,,"no, all models possess bias"
The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models,,,,,,1,"gpt-3.5-turbo, gpt-3.5-turbo-instruct, mistral-7B-v0.1, vicuna-7b-v1.5, flan-t5-xxl, flan-ul2",http://arxiv.org/abs/2404.08760v4,,,1,,1,1,1,,,,,,global,,,1,,,"US, China, Germany, Great Britain, Indonesia, Malaysia, Argentina, Brazil, Ethiopia, Nigeria",,,"18-24, 25-34, 35-44, 45-54, 55-64, 65+",,,,,,,,"no, ""we have shown that LLMs are not repre-
sentative of the value systems of older adults"""
The Emergence of Economic Rationality of GPT,,1,,,,,gpt-3.5-turbo,http://arxiv.org/abs/2305.12763v3,,,1,,1,1,1,,,,,,explicitly US,1,,1,binary,"african american, asian",,,,"kid, elder","elementary, college",,,,,,,"no, GPTâs decisions are largely rational in each domain and demonstrate higher ra-
tionality score than those of human subjects"
Artificially Intelligent Opinion Polling,,1,,,,,gpt-3.5-turbo,http://arxiv.org/abs/2309.06029v1,,,1,,,,1,,,,,,explicitly US,,1,1,binary,"white, black, hispanic, asian, other","0-17, 18-24, 25-34, 35-44, 45-54, 55-64, 65+",US state,,,"no formal education, completed high-school but not college, obtained Bachelor degree or higher","2016 US presidential vote, registration (democrat, republican, independent), 2018 Midterm election vote, 2020 us presidential election vote",,,,,,"yes, We show LLMs tend to broadly agree with humans in their annotations of
social-media users"
IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language,,,1,,,,gpt-3.5-turbo,http://arxiv.org/abs/2406.19349v1,,,1,,1,1,1,,,,,,Indonesian people,1,,1,binary,"chinese, indigeneous, other",,domicile information,,"18-24, 25-34, 35-44, 45-54","High school degree, associate's degree, bachelor's degree, master's degree",presidential vote,"with disability, no disability","islam, christian or catholics, hinduism or buddhism, ahmadiyya or shia, traditional beliefs","employed, college student, housewife or unemployed",,"LGBTQ+ (yes, no)","yes, We demonstrate how incorporating demographic information can enhance the zero-shot performance of the large language model, gpt-3.5-turbo"
"Ask LLMs Directly, ""What shapes your bias?"": Measuring Social Bias in Large Language Models",,,,,,1,"llama7b, llama13b, llama70b, gpt-3.5, gpt-4",http://arxiv.org/abs/2406.04064v1,,,1,,1,1,1,,,,,,explicitly US,1,1,,,"African, African American, Arab, Asian, Black,
Caucasian, European, Hispanic, Jewish, Latino,
Middle Eastern, Native American, Roma, South
American, White",,,,"boy, girl, kid, man, woman, elder",,,,"Atheist, Buddhist, Catholic, Christian, Hindu, Jewish, Mormon, Muslim, Protestant, Sikh","(High SES)
optometrist, chemist, dentist, psychologist, scientist,
professor, physician, lawyer, judge, physics teacher,
chemical engineer, pharmacist
(Low SES)
truck driver, cashier, line cook, server, bartender,
janitor, sales clerk, parking attendant, farm worker,
taxi driver, construction worker, receptionist","straight, gay, lesbian, bisexual, pansexual ",,"n/a, The
analysis we conducted shows that our proposed
metrics capture the multi-dimensional aspects
of social bias, enabling a fine-grained and com-
prehensive investigation of bias in LLMs (no outcome, just a framework)"
AI-Press: A Multi-Agent News Generating and Feedback Simulation System Powered by Large Language Models,1,,,,,,gpt-4o,http://arxiv.org/abs/2410.07561v1,,1,,,,,1,1,,,,,implicitly US: New York Times Dataset ,1,,,binary,,,,,"youth, middle-aged, elderly","Below Bachelor's, Bachelor's degree, Postgraduate education","liberal, moderate, conservative",,,"low income, middle income, high income",,employment,"yes, verifies the
effectiveness of public feedback simulation"
"MisinfoEval: Generative AI in the Era of ""Alternative Facts""",,,,,,1,gpt-4,http://arxiv.org/abs/2410.09949v2,,1,,,,,1,,,,,,explicitly US,,1,1,binary,white,,,,"30-49, 50-64","educated, uneducated","moderate, conservative",,,,,,yes
Donald Trumps in the Virtual Polls: Simulating and Predicting Public Opinions in Surveys Using Large Language Models,,1,,,,,gpt-4o,http://arxiv.org/abs/2411.01582v1,,,1,,1,1,1,,,,,,US and China,1,,,binary,"non-hispanic white, non-hispanic black, hispanic, non-hispanic asian/ native hawaiian / other pacific islander, non-hispanic native american/ Alaska Native, non-hispanic of multiple races",,"US state, Chinese province",,in years,"childhood education, primary education, lower secondary education, upper secondary education, post-secondary non tertiary education, short-cycle tertiary education, bachelor, master, doctoral",,,"protestant, roman-catholic, orthodox-christian, LDS, Jewish, Muslim, Buddhist, Hindu, Atheist, Agnostic, minority religious group",,,"marital status, occupati","yes, These findings suggest that LLMs could serve as effective supplements to traditional
survey methodologies"
Implicit bias in large language models: Experimental proof and implications for education,,,,,,1,gpt-3.5,https://doi.org/10.1080/15391523.2024.2395295,2024,,1,,1,1,1,,,,,,not specified,,1,1,,"Black, White",,,,,school type,,,,"upper class, lower class",,,no
Application of Large Language Models in Stochastic Sampling Algorithms for Predictive Modeling of Population Behavior,1,,,,,,GPT-3.5-Turbo,https://doi.org/10.54941/ahfe1004637,2024,,1,,,,1,,,,,,not specified,1,,,,,,,,"22-29, 30-44, 45-60",,,,,"26000 - 45000, 60000-85000, 100000-135000",,,"yes, the method is valid in generating
expected macroscopic behavioral results from a synthetic population."
Risks of Discrimination Violence and Unlawful Actions in LLM-Driven Robots,,,,,,1,"GPT-3, BERT",https://doi.org/10.54097/taqbjh83,2024,1,,,1,1,1,,,,,,not specified,,1,1,,1,1,,,,,,1,,,,,no
Popular LLMs Amplify Race and Gender Disparities in Human Mobility,,,,,,1,"GPT-4o, Gemini-1.5 pro, Claude-3.5-sonnet",https://doi.org/10.48550/arxiv.2411.14469,2024,,1,,1,1,1,,,,,,implicitly US,,1,1,binary ,"white, black hispanic, asian ",,,,,,,,,,,,no 
Challenges in Annotating Datasets to Quantify Bias in Under-represented Society,,,,,,,GPT-2,http://arxiv.org/abs/2309.08624v1,,1,,,1,1,1,,,,,,People from New Zealand,,1,,pronoun,"white, brown, Pakeha, Maori, Pacific, NZ",,,,,,,,,"poor, labourer",,,no
Open (Clinical) LLMs are Sensitive to Instruction Phrasings,,,,,,1,"MISTRAL, LLAMA 2,  ALPACA, CLINICAL-CAMEL, ASCLEPIUS, MEDALPACA",http://arxiv.org/abs/2407.09429v1,,,1,,1,1,1,,,,,,"undefined, from hospital records",,1,,"male, female","white, non-white",,,,number,,,,,,,,
LLMs generate structurally realistic social networks but overestimate political homophily,1,,,,,,"GPT-3.5 Turbo, GPT-4o, Llama 3.1 (8B and 70B), Gemma 2 ",http://arxiv.org/abs/2408.16629v1,,,1,general distributions,1,,1,,,,,,implicitly US population,1,1,,"man, woman, non-binary","white, hispanic, black, asian, American Indian/Alaska Native,
Native Hawaiian/Pacific Islander",,,,1,,"democrat, repubican, independent",,"Protestant, Unreligious, Catholic, Jewish, Hindu, Buddhist, Muslim, Other Christian",,,"hobbies, interests",partial
"Tell, don't show: Declarative facts influence how LLMs generalize",,,,,,1,"LLaMa 2, GPT 3",http://arxiv.org/abs/2312.07779v1,ask Marlene,,1,,,1,,,1,,,,undefined,,1,,"male, female",,,,,,,,,,,,,
Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets,,,1,,,,"Llama-3-8B-Instruct, Phi-3-mini-4k-instruct, SOLAR-10.7B-Instruct-v1.0, Starling-LM-7B-alpha (7B).",http://arxiv.org/abs/2410.07991v3,check with the other 2,,1,,1,1,1,,,,,,implicitly US ,1,1,1,"men, non binary, transgender men, transgender unspecified, transgender women, women, other ","asian, black, latinx, middle eastern, native american, pacific islander, white, other ",,,"immigrant, migrant worker, specific country, undocumented, other ('origin')","children, teenagers, young adults, middle aged, seniors, other ","some high school, high school, some college, college aa, college ba, master, PhD, professional degree ","neutral, slightly liberal, extremely liberal, slightly conservative, conservative, extremely conservative, no opinion ","cognitive, hearing impaired, neurological, physical, unspecific, visually impaired, other ","atheist, buddhist, christian, hindu, jewish, mormon, muslim, other, nothing ","<10K, 10Kâ50K, 50Kâ100K, 100Kâ200K, >200K ",sexuality,,partial
From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards,,,,,,1,LLaMa 2,http://arxiv.org/abs/2403.13213v4,,1,,,1,1,1,,,,,,implicitly US,,1,,"name (male, female)","name (muslim, mexican, black, jewish, white, native americans), surname (chinese, asian)",,,,,,,,,,,,no
Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data,,,,,,1,"MedAlpaca, PMC-Llama, Asclepius, ClinicalCamel, Flan-T5, Palmyra-Med, BioMedGPT, BioMistral, Llama 2, GPT-3.5, GPT-4, Gemini-2",http://arxiv.org/abs/2401.06866v2,,,1,,,,1,,1,,,,undefined,,1,,"male, female",,,,,number,,,,,,,"height, weight",yes
Evaluating Large Language Model Biases in Persona-Steered Generation,,1,,,,,"LLaMa, GPT3.5, GPT4, Tulu",http://arxiv.org/abs/2405.20253v1,,1,1,,1,1,1,,,,,,"implicitly, US population",1,1,1,"male, female","white, black",,,,,,"politically liberal, politically conservative",,,,,,no
Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting,,,,,,1,Flan-PaLM,http://arxiv.org/abs/2310.16523v1,"check with the other 2, object vs. output demographic DONE",1,,,1,1,1,,,,,introduced methodology: CCSV (collective-critiquing and self-voting); CAI (Bai et al.); CoT,not specified,,1,1,"male, female, other",ethnicity (does not specify) ,,,,,,,,,,,,yes
BEADs: Bias Evaluation Across Domains,,,,1,,,"LLaMa, Mistral",http://arxiv.org/abs/2406.04220v3,"double check, only the language generation task is in scope",1,,,,,1,,1,,,,undefined,,1,,"male, female","asian, black, hispanic, white",,,,,,,,"Christian, Muslim, Hindu, Buddhist",,,,yes
Promoting Equality in Large Language Models: Identifying and Mitigating the Implicit Bias based on Bayesian Theory,,,,,,,LLaMa 3 ,http://arxiv.org/abs/2408.10608v1,double check with Marlene,,1,,1,,,,,,,editing,undefined,1,1,,1,1,1,,,1,,,1,,,,,yes
PHEE: A Dataset for Pharmacovigilance Event Extraction from Text,,,,,,1,"SciFive
",http://arxiv.org/abs/2210.12560v1,,,1,,1,,,,1,,,,undefined,,1,,"male, female","included, no categories defined",,,,number,,,,,,,disorder,yes
Fair Wasserstein Coresets,,,,,,1,"GPT3.5, GPT4",http://arxiv.org/abs/2311.05436v4,,,1,,,1,1,,,,,,undefined,,1,,"included, no categries defined",,,,,,,,,,,,,yes
Understanding Intrinsic Socioeconomic Biases in Large Language Models,,,,,,1,"Falcon, Llama 2, GPT-2",http://arxiv.org/abs/2405.18662v1,,,1,,1,1,1,,,,,,implicity US,,1,,"name, categories (âmenâ,âboysâ, âfathersâ, âdadsâ,âgrandfathersâ,âyour sonsâ,
âyourgrandsonsâ,âyour nephewsâ,âwomenâ,âgirlsâ,âmothersâ,âmomsâ,
âgrandmothersâ,âyour daughtersâ,âyour grandaughtersâ,âyour niecesâ
)","name, categories (âWhite peopleâ, âBlack peopleâ, âAsian peopleâ, âLatino peopleâ,
âArab peopleâ, âIndigenous peopleâ, âMixed-race peopleâ, âMulti-ethnic peopleâ)",,,,,,,,"âMuslim peopleâ, âHindu peopleâ, âBuddhist peopleâ, âTaoist peopleâ,
âShintoist peopleâ, âSikh peopleâ, âJewish peopleâ, âChristian peopleâ",,,marital status,no
SPICA: Retrieving Scenarios for Pluralistic In-Context Alignment,,,,,,1,"LLama 3, GPT4o",http://arxiv.org/abs/2411.10912v1,check with the other 2,1,,,1,1,1,,,,,introduced methodology: SPICA (Scenarios for Pluralistic In-Context Alignment),"US demographically-constructed groups based on US
participants",,1,1,,,,,,,,"Repulican, Democrat",,regular participation in religious activities: yes or no,,,,partial
Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases,,,,,,1,"Gemini Ultra, MedLM Medium",http://arxiv.org/abs/2409.09201v2,,1,1,,1,1,1,,,,,,undefined,,1,,"male, female, non-binary","Asian, Black and White",,,,number,,,,,,,,partial
Are Large Language Models Ready for Travel Planning?,,,,,,1,"Gemma-2-9b, Llama-3-8b, and Llama-3-70b",http://arxiv.org/abs/2410.17333v1,,1,,,1,1,1,,,,,,undefined,,1,,"man, woman, gender minority group","African American, Hispanic, Asian, Caucasian",,,,"young adult, middle
age, elderly","no bachelor, bachelor, postgraduate",,,,"low, middle, high",,traveling interests,mixed
Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems,,1,,,,,"Blender model, ChatGPT, Alpaca, Vicuna, StableLM, FalconLM.",http://arxiv.org/abs/2310.05280v5,,1,,,1,1,1,,,,,,,1,,1,"name, woman, man, non-binary, transgender","name, African American, Asian, Black, Hispanic, Indian, Pacific Islander, White",,,,,"uneducated, primary school, middle school, high school, college, graduate","political figure, socialism, populism, nationalism, liberalism, fascism, democracy, conser-
vatism, communism","musculoskeletal disorders, special senses and speech, respiratory disor-
ders, cardiovascular system disorders, digestive system disorders, geni-
tourinary disorders, hematological disorders, skin disorders, endocrine
disorders, congenital disorders, neurological disorders, mental disorders,
cancer, immune system disorders, no disabilities","sikhism, judaism, islam, hinduism, christianity , buddhism, atheism","lower class, middle class, upper class","bisexual, gay, straight, pansexual, asexua",profession,no
Cross-Care: Assessing the Healthcare Implications of Pre-training Data on Language Model Bias,,,,,,1,"Mamba, Pythia, Llama2, Llama3, Mistral, Qwen1.5",http://arxiv.org/abs/2405.05506v2,mention to Marlene re data attribution,,1,,1,1,1,,,1,,,American population,,1,,"male, female","Asian, Black, Hispanic, Indigenous, Pacific Islander, White",,,,,,,,,,,medical conditions,no
DiversityMedQA: Assessing Demographic Biases in Medical Diagnosis using Large Language Models,,,,,,1,"GPT-3.5 Turbo, GPT-4 Turbo, GPT-4o,
Llama3-8B, Gemini-1.5",http://arxiv.org/abs/2409.01497v1,,,1,,1,1,1,,,,,,"undefined, implicitly american",,1,,1,1,,,,,,,,,,,,partial
Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity,,1,,,,,"GPT3.5, GPT4",http://arxiv.org/abs/2309.06364v3,Marlene to check,1,,,,,1,,,,,,outpatient cardiology clinics in the UK,1,,,"1, name",,,1,,1,,,,,,,health issues,no
"Understanding Biases in ChatGPT-based Recommender Systems: Provider Fairness, Temporal Stability, and Recency",,,,,,1,ChatGPT,http://arxiv.org/abs/2401.10545v3,,1,,,1,,1,,,,,,undefined,,1,,1,,,,,1,,,,,,,,partial
"""A Woman is More Culturally Knowledgeable than A Man?"": The Effect of Personas on Cultural Norm Interpretation in LLMs",,,,,,1,"GPT4o, Gemma, LLaMa 3, Mistral",http://arxiv.org/abs/2409.11636v1,,,1,,1,1,1,,,,,,undefined,1,1,,"1 (a man, a woman, a transgender man, a transgender woman, a non-binary person)","1 (a White person, a Black person)",,1 (for object),,"1 an old person, a young person","1 (a person who is a high school graduate, who has an associate degree in college,
a person who has a bachelorâs degree in college, a person who has a doctoral
degree, a person who has less than a high school degree)",,"1 (a physically disabled person, an able-bodied person)",,"1 (a lower-class person, a middle-class person, a higher-class person, a low-income person, a high-income person)",,"skintone, appearance, profession, beauty, cultural awareness",partial
Language Model Alignment in Multilingual Trolley Problems,,,,,,,"Llama 2, LLama 3, Gemma 2, Mistral, Phi, Qwen 2, GPT-3, GPT-4",http://arxiv.org/abs/2407.02273v4,,,1,,1,1,1,,,,,,global population,,1,,1,,,,,1,,,,,1,,fitness,no
Toward Fairness in Text Generation via Mutual Information Minimization based on Importance Sampling,,,,,,,GPT2,http://arxiv.org/abs/2302.13136v1,,,1,,,1,,,,,,1,undefined,,1,,"1 (male, female)",,,,,,,,,,,,,yes
"White Men Lead, Black Women Help? Benchmarking Language Agency Social Biases in LLMs",,,,1,,,"ChatGPT, Llama3, Mistral.",http://arxiv.org/abs/2404.10508v4,,1,,,1,1,1,,,,,,"undefined, implicitly american",,1,,"male, female (using names)","white, black, hispanic, asian",,,,,,,,,,,"occupation, department",no
Robustness and Confounders in the Demographic Alignment of LLMs with Human Perceptions of Offensiveness,,,1,,,,"GPT4, Gemini 1.5",http://arxiv.org/abs/2411.08977v1,Marlene,,1,,1,1,1,,,,,,"undefined, implicitly american",,1,,"1 (man, woman)","1 (asian, black, white, hispanic)",,,,,,,,,,,,no
Whose Opinions Do Language Models Reflect?,,,,,,1,"GPT3, ",http://arxiv.org/abs/2303.17548v1,,,1,,1,1,1,,,,,,American ,1,,1,"Male, Female","White, Black, Asian, Hispanic, âOther",,"Northeast, Midwest, South, West","citizenship (yes, no)","18-29, 30-49, 50-64, 65+","Less than high school, High school graduate, Some
college, no degree, Associateâs degree, College graduate/
some postgrad, Postgraduate","Republican, Democrat, Independent, Something
else",,"Protestant, Roman Catholic, Mormon, Orthodox,
Jewish, Muslim, Buddhist, Hindu, Atheist, Agnostic,
Other, Nothing in particular","Less than $30,000, $30,000-$50,000, $50,000 -$75,000,
$75,000-$100,000, $100,000 or more",,marital status,mixed
Exploring Social Desirability Response Bias in Large Language Models: Evidence from GPT-4 Simulations,,1,,,,,GPT4,http://arxiv.org/abs/2410.15442v1,,,1,,1,1,1,,,,,,global population,1,,,1,,,,,1,1,,,,1,,"marital status, household size, perceived economic circumstances.",mixed
Step by Step to Fairness: Attributing Societal Bias in Task-oriented Dialogue Systems,,,,,,1,"GPT2, BART, T5",http://arxiv.org/abs/2311.06513v2,,1,,,1,1,,,1,,,"pre-finetuning, cross training",undefined,,1,,1,1,,,,1,,,,,,,,yes
LLMs are Biased Teachers: Evaluating LLM Bias in Personalized Education,,,,,,1,"GPT4, GPT3.5, Claude 3.5, Gemini, LLaMa 3, Mistral",http://arxiv.org/abs/2410.14012v1,,1,,,1,1,1,,,,,,"undefined, implicitly US",1,1,,"male, female, non-binary, transgender man, transgender woman","asian, black, white, native american, hispanic",,,"international, immigrant, refugee",,,,"physcially disabled, able-bodied, neurotypical, neurodivergent","christian, hindu, muslin, jewish, buddhist, atheist, agnostic","low income, middle income, high income",,,no
Can AI Relate: Testing Large Language Model Response for Mental Health Support,,,,,,1,GPT4,http://arxiv.org/abs/2405.12021v2,,1,,,1,1,1,,,,,,undefined,,1,,"male, female  ","white, black, asian",,,,,,,,,,,,mixed
Which Demographics do LLMs Default to During Annotation?,,,1,,,,"GPT4, Claude",http://arxiv.org/abs/2410.08820v2,,,1,,1,1,1,,,,,,US population,1,,1,"male, female, non-binary ","asian, black, white, hispanic/latino, other",,,,,"highschool, college, graduate, other",,,,,,"occupation, zodiac, hobbies, favorite color",mixed
Evaluation of Bias Towards Medical Professionals in Large Language Models,,,,,,1,"(GPT-4, Claude-3-haiku, and Mistral-Large",http://arxiv.org/abs/2407.12031v1,,,1,,1,1,1,,,,,,Physician Data from American colleges,,1,,"male, female","white, black, hispanic, asian",,,,,,,,,,,,mixed
Large language models should not replace human participants because they can misportray and flatten identity groups,,1,1,,,,"Llama-2-Chat 7B, Wizard Vicuna 7B, GPT-3.5-Turbo, GPT-4",http://arxiv.org/abs/2402.01908v2,,1,1,,1,1,1,,,,,increasing temperature,US population,1,,,"women, men, non-binary people","Black, White, Asian",,,,"Baby Boomer: 59-77, Millennial: 27-42, Generation Z: 18-26",,,"ADD or ADHD; impaired vision like blind, low vision, colorblind; no disability",,,,,no
Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks,,1,,,,,"ChatGPT, GPT-4o mini, Mistral, LLaMA 3.1",http://arxiv.org/abs/2406.17232v2,,,1,,,,1,,1,,,,undefined,1,,,1,1,,1,,1,1,1,,,1,,population of location,mixed
GPTBIAS: A Comprehensive Framework for Evaluating Bias in Large Language Models,,,,,,,"OPT, BLOOMZ, LLaMA, GPT3, GPT3.5",http://arxiv.org/abs/2312.06315v1,,1,,,1,,1,,,,,,undefined,,1,,1,1,1,,,1,,,1,1,1,1,physical appearance,no
Enriching Datasets with Demographics through Large Language Models: What's in a Name?,,,1,,,,"Mistral-7B-Instruct, Qwen-2-7B-Instruct, Llama-3, Yi-1.5-9B-Chat, Gemma-2-9B-it, Command, Claude-3, GPT-3.5-turbo, GPT-4o",http://arxiv.org/abs/2409.11491v1,,,1,,1,1,1,,,,,,"Florida voters, Wikipedia biographies, Hong Kong financial professionals",,1,,1,1,1,1,,1,,,,,,,,mixed
CoS: Enhancing Personalization and Mitigating Bias with Context Steering,,,1,,,1,"T0pp, Mistral",http://arxiv.org/abs/2405.01768v1,"debiasing, double check",1,,,1,1,,,,,,1,,,1,,1,1,1,,1,1,,,1,1,1,1,,yes
"AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course",,,,,,1,gpt3.5,http://arxiv.org/abs/2403.14986v1,,1,,,,1,1,,,,,,Code in Place,,1,,1,,,,,,,,,,,,,yes
MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs,,,,,,1,"Aya, Falcon, GPT3.5, LLaMa, Mistral, WizardLM, Zephyr",http://arxiv.org/abs/2406.07243v3,,,1,,1,,1,,,,,,undefined,,1,,1,,,,,1,,,1,,1,1,physical appearance,no
Leveraging Language Models and Bandit Algorithms to Drive Adoption of Battery-Electric Vehicles,,1,,,,,GPT4,http://arxiv.org/abs/2410.23371v1,,,1,,,,1,,,,,,implicitly US,1,,,1 (only one category mentioned),1,,1,,1 (number),1,1,,,,,household type,"partial, tending positive"
Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation,,,1,,,,"o1-preview, LLaMa 3, Mistral",http://arxiv.org/abs/2410.05401v1,,,1,,1,1,1,,,,,,implicitly US,,1,,"male, female",,,,,"young adult, senior citizen, early working age, late working age",,,,,,,,partial 
CLIMB: A Benchmark of Clinical Bias in Large Language Models,,,,,,1,"Mistral, LLaMA, BioMistral DARE, Meditron, Asclepius, OpenBioLLM",http://arxiv.org/abs/2407.05250v2,,1,1,,1,1,1,,,,,,implicitly US,,1,,"name (male, female)",,,,,"name (White
non-Hispanic, Black non-Hispanic, Hispanic and
Asian and Pacific Islander)",,,,,,,,no
Evaluating Biases in Context-Dependent Health Questions,,,,,,1,"gpt-3.5-turbo, llama-2-70b-chat",http://arxiv.org/abs/2403.04858v1,,1,,,1,1,1,,,,,,american society,,1,,"male, female",,,"Wyoming, Idaho, South Dakota, Massachusetts, Vermont, Hawaii",,10-70,,,,,,,,no
Evaluating and Mitigating Discrimination in Language Model Decisions,,,,,,1,Claude,http://arxiv.org/abs/2312.03689v1,,,1,,1,1,1,,,,,,implicitly US,,1,,"male, female, non-binary","Asian, Black, Hispanic, Native American, White",,,,,,,,,,,,yes
Aligning Large Language Models with Human Opinions through Persona Selection and Value--Belief--Norm Reasoning,,,,,,1,"ChatGPT, ChatGPT-it, Mistral-7B-it-v0.2, GPT-2-base, GPT-2-large, FlanT5-base, FlanT5-large",http://arxiv.org/abs/2311.08385v4,OpinionQA dataset,,1,,,,1,,1,,,,undefined,1,,,1,1,,,1,1,,1,,1,1,,marital status,yes
Benchmarking Bias in Large Language Models during Role-Playing,,,,,,1,"GPT4o-mini, DeepSeek-v2.5, Qwen1.5-110B, Llama-3, Mistral-7B",http://arxiv.org/abs/2411.00585v1,,1,1,,1,,1,,,,,,implicitly US,1,1,,"men, women, non-binary individuals, transgender men, transgender women, genderqueer people, agender individuals, two-spirit individuals, genderfluid people, bigender individuals, masculine-presenting individuals, feminine-presenting individuals, androgynous individuals, intersex individuals, cisgender men, cisgender women, older men, older women, younger men, younger women, middle-aged men, middle-aged women, teenage boys, teenage girls, boys, girls, masculine gay men, feminine gay men, lesbian women, masculine lesbian women, feminine lesbian women, bisexual men, bisexual women, pansexual individuals, asexual individuals, heterosexual men, heterosexual women, gender non-conforming individuals, queer individuals, questioning individuals, bear community members, lipstick lesbians, butch lesbians, femme gay men, transgender youth, transgender elders, drag queens, drag kings, cross-dressers, gender activists","African Americans, Caucasians, Hispanic Americans, Asian Americans, Native Americans, Middle Easterners, Pacific Islanders, Black Africans, Latino/as, East Asians, South Asians, Southeast Asians, Indigenous Australians, Roma, Jews, Armenians, Kurds, Basques, Sikhs, Hmong, Vietnamese, Filipinos, Chinese, Japanese, Thai, Malays, Tamils, Afghans, Persians, Palestinians, Lebanese, Syrians, Tutsi, Hutu, Berbers, Maori, Inuit, Samoans, Fijians, Tahitians, Chicanos, Creoles, Mestizos, Afro-Caribbeans, Afro-Latinos, Arabs, Slavics, Anglo-Saxons, Celts, Zulus",,,,"Teenagers, Young adults, Middle-aged professionals, Senior citizens, College students, High school students, Retired individuals, Working parents, Single parents, Stay-at-home parents, Empty nesters, Young professionals, Elderly care workers, Juvenile delinquents, Child prodigies, Military veterans, Recent retirees, New grandparents, Tech-savvy youth, Baby boomers, Generation X, Millennials, Generation Z, Elderly immigrants, Teen influencers, Young athletes, Senior executives, Middle-aged entrepreneurs, Young entrepreneurs, Aging politicians, Young politicians, Teenage activists, Senior community leaders, Middle-aged teachers, Young teachers, Childless couples, New homeowners, Middle-aged managers, Senior board members, Middle-aged volunteers, Youth volunteers, College graduates, Young artists, Senior artists, Youth mentors, Senior mentors, Middle-aged caregivers, Young caregivers, Youth leaders, Middle-aged leaders",,,"Hearing individuals, Sighted individuals, Neurotypical individuals, Physically able individuals, Mentally healthy individuals, Individuals without chronic illness, Individuals without disabilities, Individuals with high physical stamina, Individuals with strong cognitive abilities, Individuals with typical speech capabilities, Individuals without mobility issues, Individuals without sensory impairments, Individuals with strong mental resilience, Individuals with full motor control, Individuals without learning disabilities, Individuals without cognitive impairments, Individuals with typical emotional regulation, Individuals without anxiety disorders, Individuals without depression, Individuals without chronic pain, Individuals with high endurance, Individuals with normal vision, Individuals with normal hearing, Individuals with typical motor skills, Individuals with typical communication abilities, Individuals without developmental disorders, Individuals without neurological conditions, Individuals with normal brain function, Individuals without any physical impairments, Individuals with strong sensory processing, Individuals with normal immune function, Individuals without genetic disorders, Individuals with no need for assistive devices, Individuals without any speech disorders, Individuals without ADHD, Individuals without autism spectrum disorder, Individuals without intellectual disabilities, Individuals with typical physical coordination, Individuals with no history of mental illness, Individuals without PTSD, Individuals without substance use disorders, Individuals without bipolar disorder, Individuals with strong executive functioning, Individuals with normal muscle function, Individuals without seizure disorders, Individuals without physical deformities, Individuals without psychological disorders, Individuals without any mental health conditions, Individuals without phobias, Individuals without chronic fatigue","Christian pastors, Muslim imams, Jewish rabbis, Hindu priests, Buddhist monks, Catholic bishops, Evangelical preachers, Orthodox priests, Mormon elders, Jehovah's Witness leaders, Sikh granthis, Shinto priests, Scientology ministers, Amish bishops, Quaker elders, Pentecostal pastors, Presbyterian ministers, Lutheran pastors, Baptist pastors, Methodist ministers, Anglican priests, Unitarian Universalist ministers, Seventh-day Adventist pastors, Zen Buddhist teachers, Taoist priests, Confucian scholars, Zoroastrian priests, Rastafarian leaders, Pagan priests, Wiccan high priests, Baha'i spiritual leaders, Jain monks, Druze religious leaders, Coptic Orthodox priests, Eastern Orthodox patriarchs, Sufi sheikhs, Hasidic rabbis, Reformed Jewish rabbis, Roman Catholic cardinals, Greek Orthodox priests, Armenian Apostolic priests, Maronite priests, Melkite priests, Nestorian priests, Coptic bishops, Anglican bishops, Orthodox Jewish rabbis, Sunni Muslim clerics, Shia Muslim clerics, Unitarian ministers",,,"culture, occupation",
Can Language Models Reason about Individualistic Human Values and Preferences?,,,,,,1,"gpt4, LLaMa 3, Mistral, Mixtral, Qwen, Claude",http://arxiv.org/abs/2410.03868v1,could also be generic,,1,,1,1,1,,,1,,probing,global population,1,,,,,,"continent (Africa, North America, South America, Europe, Asia, Oceania)","immigrant, citizen","16-24, ... 65+","early childhood or none, primary, lower secondary, upper secondary, post-secondary non-tertiary, short-cycle tertiary, bechelor, master, doctoral",,,"no religion, protestant, catholic, orthodox, jewish, muslim, hindu, buddhist, other christian, other religion","upper, upper middle, lower middle, working, lower / low income, middle, high",,occupation,no
Representation Bias in Political Sample Simulations with Large Language Models,1,,,,,,GPT-3.5-Turbo,http://arxiv.org/abs/2407.11409v1,,,1,,1,1,1,,,,,,"US, Germany, China",1,,,1,1,,,,1,1,1,,1,1,,,partial 
Re-examining Sexism and Misogyny Classification with Annotator Attitudes,,,1,,,,"Flan T5, LLaMA 2 7B, LLaMA 3 8B, Mistral
7B:",http://arxiv.org/abs/2410.03543v1,,,1,,,,1,,1,,,,Mturk workers from the UK,1,1,,"male, female","white, asian, black, other",,,,24 â 56,,"Left-wing/liberal, Centre, Rightwing/conservative, None/prefer, not to say",,,,"heterosexual, bisexual, prefer not to say, don't know",,"partial, tending positive"
Capturing Bias Diversity in LLMs,,,,,,,gpt3.5,http://arxiv.org/abs/2410.12839v1,,1,,,1,1,,,1,,,,undefined,,1,,"male, female","asian, black, white, australoid",,,,"young, old",,,,,,,,yes
"Jiang, Hang, et al. ""CommunityLM: Probing partisan worldviews from language models."" arXiv preprint arXiv:2209.07065 (2022).",,,,,,,"gpt2, gpt3",https://arxiv.org/abs/2209.07065,,1,,,1,,1,,1,,,,implicitly US,"1 (political, republican/democrat)",1 (14 groups),,transgender people,"blacks, whites, Hispanics, Asians,",,,illegal immigrants,,,"Republican Party, the
Democratic Party",,,,,"American politicians, feminists, the #MeToo move-
ment, socialists, capitalists, big
business, labor unions",yes
"Bisbee, James, et al. ""Synthetic replacements for human survey data? The perils of large language models."" Political Analysis (2023): 1-16.",,1,,,,,"gpt3.5, gpt4, falcon-40b",Synthetic Replacements for Human Survey Data? The Perils of Large Language Models | Political Analysis | Cambridge Core,17.05.2024,,1,,1,1,1,,,,,,American,1,1,,"input: male, female, object: women","input: non-Hispanic white, non-Hispanic black, Hispanic Object: Black Americans? White Americans?
Hispanic Americans?
Asian Americans?",,,object: immigrants?,number,"a high school diploma, some college but no degree, a bachelorâs degree or more","input: an extremely liberal, a liberal, a slightly liberal, a moderate, a slightly conservative, a conservative, an extremely conservative / Democrat, Independent, Republican object: The Democratic Party? The Republican Party? Democrats? Republicans? Liberals?
Conservatives?",,"object: Muslims?
Christians? Jews?","$30k, $50k, $80k, $100k, $150k or more",object: Gays and Lesbians?,political interest,no
"Kim, Junsol, and Byungkyu Lee. ""AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction."" arXiv preprint arXiv:2305.09620 (2023).",,1,,,,,Alpaca-7b,https://arxiv.org/abs/2305.09620,,,1,,1,1,,,1,,,,American,1,,,"male, female","black, white, other",,"East, west, south, midwest",,18-89,"It Hs, HS grad, BS, MS+, some college","strong, weak, lean toward * democrat, republican, independent",,,"income Q1-Q5, missing",,,yes
"von der Heyde, Leah, Anna-Carolina Haensch, and Alexander Wenz. ""Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion."" arXiv preprint arXiv:2407.08563 (2024).",,1,,,,, GPT-3.5,https://arxiv.org/abs/2407.08563,,,1,,1,1,1,,,,,,German population,1,,,"male, female",,,"0 East Germany
1 West Germany","1, object",,1,"(1) CDU/CSU
(2) CDU
(3) CSU
(4) SPD
(5) FDP
(6) GRÃNE
(7) DIE LINKE
(322) AfD
(801) [other party: specify]
(808) [no party]",,,"low, middle, high",,religiosity,no
"Kalinin, Kirill. ""Improving GPT Generated Synthetic Samples with Sampling-Permutation Algorithm."" Available at SSRN 4548937 (2023).",,1,,,,,GPT 3,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4548937,2023,,1,,,,1,,,,,,Russian elites,1,,,"male, female",,,,,"young, old",,,,,,,elite status,partial
"Durmus, Esin, et al. ""Towards measuring the representation of subjective global opinions in language models."" arXiv preprint arXiv:2306.16388 (2023).",,,,,,,"a decoder-only transformer model fine-tuned with Reinforcement Learning from Human
Feedback (RLHF) [18 , 76 ] and Constitutional AI (CAI",https://arxiv.org/abs/2306.16388,,,1,,,1,1,,,,,,Global Population,1,1,1,,,,country,,,,,,,,,,partial
Coding Inequity: Assessing GPT-4's Potential for Perpetuating Racial and Gender Biases in Healthcare,,,,,,1,GPT4,https://www.semanticscholar.org/paper/060d472f6efce06bef0123c974a24fdcc54c0e6d,2023,1,,,1,1,1,,,,,,US ,,1,,"male, female","asian, black, white, hispanic",,,,,,,,,,,,no
Simulating Climate Change Discussion with Large Language Models: Considerations for Science Communication at Scale,,1,,,,,gpt4,https://doi.org/10.1145/3657604.3662033,2024,1,,,1,1,1,,,,,,implicitly US,1,,,"female, male, nonbinary","Asian, Hispanic or Latino, Pacific Islander,
Black or African American, multiracial,
American Indian or Alaska Native (Indigenous)",,,,"child, adolescent, young adult, adult, senior",,"liberal, conservative","able body, physical disability, mental health,
sensory impairment, intellectual disability,
chronic illnesses, developmental disorders",,"low-income, middle-income, high-income",,,partial
Racial Steering by Large Language Models: A Prospective Audit of GPT-4 on Housing Recommendations,,,,,,1,gpt4,https://doi.org/10.1145/3689904.3694709,2024,,1,neighborhood recommendation,1,1,1,,,,,,US,,1,1,"woman, man, gender nonconforming person","black, asian, white, hispanic, hawaian, native american",,American cities,,,,,,,housing voucher,"straight, LGBT",,no
Can ChatGPT emulate humans in software engineering surveys?,,1,,,,,chatgpt,https://doi.org/10.1145/3674805.3690744,2024,,1,,,,1,,,,,,undefined,1,,,1,,,1,,1,,,,,,,,partial
ChatGPT for Mental Health Applications: A study on biases,,,1,,,,chatgpt,https://doi.org/10.1145/3639856.3639894,2024,,1,,1,1,1,,,,,,undefined,,1,,"male, female, transgender",,,,,18-50+,,,,,,,,partial
Assessing the Predictive Power of Social Media Data-Fed Large Language Models on Vote Preference,,1,,,,,"gpt3.4, gpt4",https://doi.org/10.1145/3630744.3659831,2024,,1,,,,1,,,,,,Turkey,1,,,1,1,,1,,1,1,,,,,,,partial
Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration,,,,,,,"LLAMA2-13B, CHATGPT, LLAMA2-7B, LLAMA2-70B, LLAMA3-8B, and GEMMA-7B.",http://arxiv.org/abs/2406.15951v2,debiasing/alignment paper,,1,,1,1,1,,1,,,,"US, Global",1,1,,1,1,1 countries,1,,1,1,left/center/right-leaning perspectives,,1,1,,,yes
"Who is GPT-3? An Exploration of Personality, Values and Demographics",,,,,,,gpt3,http://arxiv.org/abs/2209.14338v2,,,1,,1,1,1,,,,,,,,,1,"1 (male, female, other)",,,,,1 (number),,,,,,,"values, personality",partial
Know Your Audience: Do LLMs Adapt to Different Age and Education Levels?,,,,,,1,"ChatGPT3, GPT-3 Da-Vinci-0003, bigscience-T0 Flan-T5. ",http://arxiv.org/abs/2312.02065v1,audit,1,,,1,1,1,,,,,,,1,1,,,,,,,11-23,"5th grd. 6th 7th 8thâ9th 10thâ12th college
students
college
grads
professional ",,,,,,,no
ROBBIE: Robust Bias Evaluation of Large Generative Language Models,,,,,,,"GPT-2, OPT, BlenderBot 3, BLOOM, LLaMa",http://arxiv.org/abs/2311.18140v1,,1,,,1,1,1,,,,,,Implicitly US,,1,,"male: maleÅ¡, malÃ¨,
males, male, mÃ¢le, male-identified, male-, malÃ©,
male-male, male., mÃ¢les. female: woman, woman.,
female-female, female, female., female-identified,
female-. transgender: transsexual, trans-gendered,
transgendered, transgender, trans-women, transgenderism, trans-woman, trans-sexual, transexuality","black: coloured,
black, dark-coloured, black-ish, black-on-black,
blackness, all-black, black-on-white, black-,
half-black, blacky, black-and, black., blackonly. white: white-only, whiteness, half-white,
white-looking, white-, whitey, all-white, whites,
whitely, whiteish, white-on-white, white-ish,
pure-white, white., white, whites.. asian: all, asian, asian-, asian-born, asians, asian-european,
asian-americans, asianists, asian, anti-asian,
asian-australian, asian-american, chinese, asianist, asian-based, asian-related, asian-indian,
asian-african, asian-canadian, asiana, half-asian,
asian-looking. latino: afro-latino, hispanico, latino,
hispanic, hispÃ¡nico, hispanic-americans, hispanic-,
hispanic-american, mexican, hispanics, latinoowned, latino-american, afro-latinos, latinoheat,
hispanicized, latinos, latinoamÃ©rica, hispanica,
latinorum, latinoamerica, hispÃ¡nica, latinoaussie,
anti-latino, latinoamerican, latino-americans, latinoamericano, latinoamericanos, latino-amÃ©ricain,
hispanicus. other_race_or_ethnicity: ethnically, ethnic-related, cross-ethnic, non-ethnic,
race-specific, other_race_or_ethnicity, ethnicy,
ethnicly, race-ethnicity, ethnicity-related, ethnicity,
multi-ethnic, other race or ethnicity, ethnicities,
ethnically-mixed, ethnics, ethnic-specific, ethnic, other-race, non-ethnically, multi-ethnicity,
racial-ethnic, ethnic-minority. ",1,,,1,,1," physical_disability:
physical disability, physical_disability, disability, disability-related, disability-specific.
intellectual_or_learning_disability: intellectual_or_learning_disability, intellectual or
learning disability, learning-disabled. psychiatric_or_mental_illness: psychiatrically, mentalhealth, psychiatric, psychiatric_or_mental_illness,
psychiatric or mental illness, mental-illness.
other_disability: other_disability, disabilityfriendly, other disability, disability-related,
disability., disability, disability-specific.","christian: christianize, christianese, christians, christian-only,
christianising, christiansand, christiany, jewishchristian, -christian, christian., christianise,
christianists, christian, christianity, christian-,
christians., christianity-, christianity., christianmuslim, muslim-christian, christianized, religious,
christian-right, christianist, christian-jewish.
jewish: judaÃ¯sme, jewish-canadian, half-jewish,
part-jewish, anglo-jewish, jewes, french-jewish,
-jewish, jewish-related, jewsish, christian-jewish,
jewish-, jewish-zionist, anti-jewish, jewish-muslim,
jewishgen, jews-, jewish-american, jewish.,",1,"heterosexual: heterosexually, heterosexual, heterosexuality, heterosexualization, heterosexuals,
heterosexualism. homosexual_gay_or_lesbian:
gay-lesbian, homosexual_gay_or_lesbian, homosexually, homosexual, gÃ¢y, lgbt, homosexual
gay or lesbian, homosexuality, gay. bisexual:
bi-sexual, bi-curious, bisexuality, bisexuals,
bisexual, bi-sexuality. other_sexual_orientation:
other sexual orientation, sexual-orientation,
other_sexual_orientation","occupation, culture, ",partial
The Impact of Inference Acceleration Strategies on Bias of LLMs,,,,,,,"LLaMa, Mistral",http://arxiv.org/abs/2410.22118v1,audit,,1,,1,1,,,,,,quantization,"US, Global",,1,,"male, female, nonbinary",1,1,,,1,,,1,1,1,1,Phsyical appearance,partial
Classist Tools: Social Class Correlates with Performance in NLP,,,,,,,"Llama 2, Mistral-7B, Zephyr-7B ",http://arxiv.org/abs/2403.04445v1,audit,,,perplexity,,1,1,,,,,,"UK, US",,1,,"male, female","white, black",,"US, UK",,,,,,,"lower, middle, upper class",,,no
Computer says 'no': Exploring systemic bias in ChatGPT using an audit approach,,,,,,1,ChatGPT,http://arxiv.org/abs/2309.07664v3,"audit, hiring",,1,,1,1,1,,,,,,Flanders,,1,,"male, female","Arab, Asian, Black American, Central African, Dutch,
Eastern European, Hispanic, Turkish, and White American",,,,,,,,,,,occupation,no
Semantics Preserving Emoji Recommendation with Large Language Models,,,1,,,1,"gpt4, gemma, lamma, mistral",http://arxiv.org/abs/2409.10760v1,,,1,,1,1,1,,,,,,,,1,,"male, female",,,,,"young, adult, child, senior",,,,,,,,yes
Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework,,,,,,,"GPT3, GPT3.5, Claude, GPT4",http://arxiv.org/abs/2403.08743v1,debiasing,,1,,1,1,1,,,,,,,,1,,"male, female, non-binary","white, Black, Asian, Hispanic, Native American]",,,,20-100,,,,,,,,yes
Leveraging generative artificial intelligence to simulate student learning behavior,1,,,,,1,ChatGPT,http://arxiv.org/abs/2310.19206v1,,,1,,1,,1,,,,,,UK students,1,1,,"male, female",,,1,,"18-21, 21-25, 25+",,,,,,,education,yes
Questioning the Survey Responses of Large Language Models,,1,,,,,"GPT-2, GPT-Neo, Pythia, MPT, LLaMA, Llama 2, GPT-3, MPT 7B, GPT NeoX 20B, Pythia 12B, the Vicuna and Koala fine-tunes of LLaMA, Llama 2 Chat, GPT-3.5, GPT-4",http://arxiv.org/abs/2306.07951v3,,,1,,,,1,,,,,,US,1,,,"male, female",1,,1,1,1,,,,,,,,no
Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information,,1,,,,,gpt3.5,http://arxiv.org/abs/2402.18144v1,,,1,,1,1,1,,,,,,US,1,,,"men, women","Asian, Black, Hispanic, White, Native American",,,,"18-30, 31-45, 45-60, 60+",,"conservative, liberal, republican, democrat, independent",,,,,,"partial, tending positive"
Aligning Language Models to User Opinions,,,,,,1,gpt3,http://arxiv.org/abs/2305.14929v1,,,1,,,1,1,,,,,,US implicit,1,,,1,1,,1,1,1,1,1,1,1,1,,marital status,yes
Demonstrations of the Potential of AI-based Political Issue Polling,,1,,,,,chatgpt,http://arxiv.org/abs/2307.04781v2,,1,1,,1,1,1,,,,,,US,1,,,"man, woman","white, non-white",,,,"1, 4 bins",,,,,,,,partial 
Who is Legion?: Surfacing Demographic Voices in Large Language Models,,1,,,,,gpt3.5,https://doi.org/10.2139/ssrn.4856328,2024,,1,,1,1,1,,,,,,,1,,1,"woman, man","American Indian, Asian, Black, Hispanic, Pacific Islander, White",,,,"young, middle age, old",,"extremely conservative, conservative, moderate; middle of the road, liberal, extremely libera",,,"very poor, poor, middle, upper",,,partial
"Enhancing In-Hospital Mortality Prediction Using Multi-Representational
  Learning with LLM-Generated Expert Summaries",,,,1,,,Med42v2-70,https://doi.org/10.48550/arxiv.2411.16818,2024,1,,,,1,1,,,,,,,,1,,,"hispanic/latino, african american, asian, black, white, other",,,,,,,,,,,,yes
Performance and biases of Large Language Models in public opinion simulation,,1,,,,,GPT3.5,https://doi.org/10.1057/s41599-024-03609-x,2024,1,1,,1,1,1,,,,,,"South Africa, Brazil, Japan, Singapore, Sweden, USA",1,,,"male, female",country specific,,,,continuous,"with uni, without uni",,,,"upper, middle, lower",,,partial
"Large language models, social demography, and hegemony: comparing authorship in human and synthetic text",,,,1,,,"gpt3.5, gpt4",https://doi.org/10.1186/s40537-024-00986-7,2024,1,,,1,1,1,,,,,,UC students,,1,,"male, female",,,,,,,,,,economic connectedness,,,no
Gastrogpt: Development and Controlled Testing of a Proof-Of Concept Customized Clinical Language Model,,,,,,1,"GastroGPT, GPT-4, Bard, Claude",https://doi.org/10.2139/ssrn.4718227,2024,1,,,1,,,,1,1,,,,,1,,1,,,,,16-65+,,,,,,,,yes
Addressing Gender Bias in Generative Large Language Models,,,,,,,"LLaMa, BLOOM, Gemma, Mistral",https://doi.org/10.21203/rs.3.rs-4670889/v1,2024,1,,,,,,,,,,quantization,,,1,,1,,,,,,,,,,,,,yes
Chasing sleep physicians: ChatGPT-4o on the interpretation of polysomnographic results,,,,,,1,gpt4o,https://doi.org/10.1007/s00405-024-08985-3,2024,,1,,,,1,,,,,,,,1,,"male, female",,,,,cohorts,,,,,,,,"partial, tending positive"
"Different Bias Under Different Criteria: Assessing Bias in LLMs with a
  Fact-Based Approach",,,,,,1,"Llama2, Llama3, Llama3.1, Mistral, Qwen1.5,
and Qwen2, gpt3.5, gpt4",https://doi.org/10.48550/arxiv.2411.17338,2024,,1,,1,,1,,,,,,US,1,1,,"male, female",,,,,"44 years and below,45 years and above",,,,,,,,no
Fine-tuned large language models for answering questions about full-text biomedical research studies,,,,,,1,"GPT-4o-mini (GPT-4o), Llama3.1-8B-Instruct (Llama3.1-8B), and Llama3.1-70B-Instruct (Llama3.1-
23 70B) ",https://doi.org/10.1101/2024.10.28.24316263,2024,,1,,,,,,1,,,,,,1,,,,,1,,1,,,,,,,,yes
Dissecting bias of ChatGPT in college major recommendations,,,,,,1,gpt3.5,https://doi.org/10.1007/s10799-024-00430-5,2024,1,,,1,1,1,,,,,,California students,,1,,"male, female, lgbtq","American Indian or Alaskan Native, Asian, Black or African American, Filipino, Hispanic or Latino, Native Hawaiian or Pacific Islander, White",,,,,,,,,"disadvantaged, non-disadvantaged",,,no
"AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering
  Benchmark Dataset",,,,,,1,"Phi-3, GPT4, MedLM, Claude 3, OpenBioLLM, Gemini, Meditron, MedLlama",https://doi.org/10.48550/arxiv.2411.15640,2024,1,1,,,1,1,,,,,,Africa,,1,,,,,African countries,,,,,,,,,,no
Impact of Demographic Modifiers on Readability of Myopia Education Materials Generated by Large Language Models,,,,,,1,"ChatGPT, Gemini, and Copilot",https://doi.org/10.2147/opth.s483024,2024,1,,,1,1,1,,,,,,implicitly US,,1,,"male, female","Asian, Black, Hispanic, Native American, and White.",,,,,,,,,,,,partial
Enhancing Patient-Physician Communication: Simulating African American Vernacular English in Medical Diagnostics with Large Language Models,,,,,,1,gpt4,https://doi.org/10.21203/rs.3.rs-5279660/v1,2024,1,,,,,1,,,,,,US,,1,,,Black,,,,,,,,,,,,partial
"Bank Run, Interrupted: Modeling Deposit Withdrawals with Generative AI",,1,,,,,gpt4,https://doi.org/10.2139/ssrn.4656722,2023,1,1,,1,1,1,,,,,,US,1,,,"female, male",,,,,"18-24, 25-34, 35-54, 55-64, 65+","no high-school, high-school, college, graduate",,,,"under $25K, $25K - $50K-, $50K - $75K-, $75K - $120K, over $120K",,,yes
"Plastic Surgery and Artificial Intelligence: How ChatGPT Improved Operation Note Accuracy, Time, and Education",,,,,,1,chatgpt4,https://doi.org/10.1016/j.mcpdig.2023.06.002,2023,1,,,,,1,,,,,,,,1,,1,,,,,1,,,,,,,,yes
Segmentation using large language models: A new typology of American neighborhoods,,,1,,,,gpt4,https://doi.org/10.1140/epjds/s13688-024-00466-1,2024,1,,,,,1,,,,,,US,,1,,,1,,1,,,,,,,1,,,yes
"Unveiling Performance Challenges of Large Language Models in
  Low-Resource Healthcare: A Demographic Fairness Perspective",,,,,,1,"GPT4, Claude-3, LLaMA-3 (8b) ",https://doi.org/10.48550/arxiv.2412.00554,2024,1,1,,1,1,1,,1,,,agents,,,1,,"male, female","african american, white, hispanic, asian",,,,,,,,,,,,no
Comparison of Large Language Models Versus Traditional Information Extraction Methods for Real World Evidence of Patient Symptomatology in Acute and Post-Acute Sequelae of SARS-CoV-2,,,,,,1,LLaMA2-13b-chat,https://doi.org/10.20944/preprints202409.1518.v1,2024,1,,,1,1,1,,1,,,,U.S,,1,,"male, female","asian, black, white, hispanic, other",,,,,,,,,,,,partial
Evaluating the capability of ChatGPT in predicting drugâdrug interactions: Realâworld evidence using hospitalized patient data,,,,,,1,chatgpt,https://doi.org/10.1111/bcp.16275,2024,,,,,,,,,,,,,,1,,1,,,,,1,,,,,,,,no
Fairness Identification of Large Language Models in Recommendation,,,,,,1,ChatGLM3-6B and Llama2-13B,https://doi.org/10.21203/rs.3.rs-5228643/v1,,,1,,1,,1,,,,,,,,1,,1,,,,,1,,,,,,,,yes
"Moral Mimicry: Large Language Models Produce Moral Rationalizations
Tailored to Political Identity",,,,,,1,"GPT, OPT, GPT3.5",https://arxiv.org/pdf/2209.12106,,1,,,,1,1,,,,,,US implicit,1,,,,,,,,,,"liberal, conservative",,,,,,partial
Aligning with Whom? Large Language Models Have Gender and Racial Biases in Subjective NLP Tasks,,,1,,,,"FLAN-T5-XXL, FLAN-UL2, GPT-3.5, GPT-4",http://arxiv.org/abs/2311.09730v1,,,1,,1,1,,,,,,,US population,1,,,"1 (Woman, Man)","1 (Black, Asian, White)",,,,,,,,,,,,no
Exploring Safety-Utility Trade-Offs in Personalized Language Models,,,,,,1,"Llama2-13B, Llama2-70B, Llama3-8B, Llama3-70B. Mistral-7B, GPT-3.5, GPT-4o, Mixtral 8x7B, OpenHermes-2.5-Mistral-7B",http://arxiv.org/abs/2406.11107v1,,1,,,1,1,,,,,,DPO (Direct Preference Optimization),US population (implicit),,1,1,"1 (man, woman, transgender man, transgender woman, non-binary person)","1 (African, Hispanic, Asian, Caucasian, African-American, Native American)",,,,"1 (minor, teenager, adult, middle-aged person, senior citizen)",,"1 (Democrat, Republican, Independent","1 (physically disabled, able-bodied)","1 (Jewish, Christian, Atheist, Muslim, Hindu)",,"1 (straight, gay, lesbian, bisexual, asexual)",,no
On the Conversational Persuasiveness of Large Language Models: A Randomized Controlled Trial,,,,,,1,GPT-4 ,http://arxiv.org/abs/2403.14380v1,,1,1,closed; evaluation of pesruasiveness on Likert-Scale (before and after); comparing closed score changes of LLM debates with human debates; open with analytic emotional features etc.,1,1,1,,,,,,US adults,,1,1,"female, male, other","White, Black, Asian, Latino, Mixed, Other",,,,"18-24, 25-34, 35-44, 45-54, 55-64, 65+","no degree,high-school-degree, vocational, bachelor, master, phd","democrat, republican, independent, other",,,"self-employed, employed for wages, unemployed, student, retired, other",,,"no, GPT-4 with access to personal information has higher persuasive power than humans; humans can correctly identify their opponent as AI"
Exposing Bias in Online Communities through Large-Scale Language Models,,,,,,,GPT-Neo-1.3B,http://arxiv.org/abs/2306.02294v1,,1,,,1,1,,,1,,,,"bias towards: not specified, bias of: online communities",,1,1,"1 (women, men, transgender people)","1 (Asian, Black, White)",,,,,,,,"1 (Christian, Jewish, Muslim)","1 (poor, rich)","1 (asexuality, bisexuality, heterosexuality, homosexuality)",,no
Secret Keepers: The Impact of LLMs on Linguistic Markers of Personal Traits,,,,1,,,"GPT3.5, Llama 2 70B, Gemini pro",http://arxiv.org/abs/2404.00267v2,,1,,,1,1,,,,,,,US congress speakers (for demographic dimensions),,1,1,"male, female",,,,,"27-40, 41-55, 56-70, over 70",,"Republicans, Democrats",,,,,"personality (openness, conscientiousness, extraversion, agreeableness, neuroticism), dispositional empathy (perspecitve-taking, fantasy, empathetic concern, personal distress), morality (care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, purity/degradation)",partial
PERSONA: A Reproducible Testbed for Pluralistic Alignment,,1,,,,,"GPT-4, Llama 3 70B, Qwen2 72b, Mistral large",http://arxiv.org/abs/2407.17387v1,,,1,,,,,,,,,,US population,1,,,1,1,1,,1?,1,1,1,1,1,1,,many more (33 in total),yes
Quantitative Certification of Bias in Large Language Models,,,,,,,"Vicuna-7B, Vicuna-13B, Llama-7B, Llam-13B, Mistral-7B, Gemini, GPT-3.5, GPT-4, Claude-3.5-Sonnet",http://arxiv.org/abs/2405.18780v2,,1,,,,,,,,,,,not specified  ,,1,1,"male, female","black, white, (asians only in appendix)",,,,,,,,,,,,partial
Group Preference Optimization: Few-Shot Alignment of Large Language Models,,,,,,1,"Alpaca 7B, Llama 7B, Llama 13B chat",http://arxiv.org/abs/2310.11523v2,,,1,,1,1,,,,,,in-context meta-learning,"US population, global population",,1,1,"Male, Female","Black, White, Asian, Hispanic",,"Northeast, South",,,"College graduate/some postgrad, Less than high school","political ideology (Liberal, Conservative, Moderate), political party (Democrat, Republican)",,"Protestant, Jewish, Hindu, Atheist, Muslim","More than $100K+, Less than $30,000",,,yes
On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts,,,,,,1,"ChatGPT, Ging Chat, Google BARD",http://arxiv.org/abs/2410.10850v2,,1,,,,,,,,,,,not specified,,1,1,,1,,1,,1,,,,,,,,no
Human Mobility Modeling with Limited Information via Large Language Models,,1,,,,,"GPT-4, Llama2-70b",http://arxiv.org/abs/2409.17495v1,,,1,,,,,,,,,,US population (California),,1,1,1,,,1,,,1,,,,1,,,yes
Prompting GPT-3 To Be Reliable,,,,,,,GPT-3,http://arxiv.org/abs/2210.09150v2,,,1,,1,,,,,,,,not specified,,1,1,1,1,1,,,1,,,1,1,1,1,physical appearance,partial
Is persona enough for personality? Using ChatGPT to reconstruct an agent's latent personality from simple descriptions,,1,,,,,"GPT-3.5-Turbo, GPT-4-Turbo",http://arxiv.org/abs/2406.12216v1,,,1,,1,,,,,,,,not specified,1,,,"male, female",,,,,"[18, 30), [30, 50), [50, 65), [65, 80)",,,,,"[26,500, 52,000), [52,000, 156,000), [156,000, 223,000]",,"marital status (single, married, divorced), number of children (no child, one child, more than one child), personality (Honesty-Humility, Emotionality, Extraversion, Agreeableness, Conscientiousness, Openness to Experience)",yes
Quantifying the Persona Effect in LLM Simulations,,,1,,,,"GPT-4, GPT-3-Turbo, Llama-2-7b/13b/70b, Llama-2-chat-7b/13-b/70b, Tulu-2-70b, Tulu-2-dpo-7b/13b/70b",http://arxiv.org/abs/2402.10811v2,,,1,,1,,,,,,,,"11/11 datasets use US population, 4/11 also include other countries",1,,1,1,1,1,1,,1,1,1,,,1,1,"impact of Technology, Parental Status, uses social media sites, uses news media sites, religion important, tocix content a problem, uses community forums, uses video sites, occupation",partial
Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas,,1,,,,,GPT-3.5-Turbo ,http://arxiv.org/abs/2408.06929v1,,,1,,1,1,,,,,,,European nationals,1,,,1,,,"Austria, France, Germany, Greece, Ireland, Israel, italy, Netherlands, Norway, Poland, Romania, Spain, Sweden, Switzerland, United Kingdom",,1,1,1,,,,,,partial
MBIAS: Mitigating Bias in Large Language Models While Retaining Context,,,,,,,Mistral2-7B-instruct,http://arxiv.org/abs/2405.11290v3,,1,,,1,1,,,1,,,,not specified (US population?),,1,1,Women,"Black, Asian, Native American, Middle Eastern, Latino, Mexican(?)",,,,,,,"Mental Disability, Physical Disability","Muslim, Jewish",,LGBTQ,,yes
Large Language Models Can Infer Personality from Free-Form User Interactions,,,1,,,,ChatGPT,http://arxiv.org/abs/2405.13052v1,,,1,,1,1,,,,,,,US participants,,1,1,"male, female","white,non-white",,,,">36, >36","no college education, college education",,,,"< $50K, > 50K",,,partial
On the steerability of large language models toward data-driven personas,,,,,,1,"GPT-Neo-1.3B, GPT-Neo-2.7B, GPT-j-6B, Falcon-7B-Instruct",http://arxiv.org/abs/2311.04978v2,,,1,,1,1,,,,,,prefix tuning,US population,1,,,"female, male, in some other way, other","White, Black, Asian, Hispanic, Mixed Race, Other",,"West, South, Northeast, Midwest, other","citizenship (of the US), no citizenship, other","18-29, 30-49, 50-64, 65+, other","Less than high school, high school graduate, some college, no degree, associate's degree, college graduate/some postgrad, postgraduate, other","Very conservative, conservative, moderate, liberal, very liberal, other - Democrat, Republican, Independent, other",,"Hindu, Buddhist, Muslim, Jewish, Christian, Roman Catholic, Orthodox, Protestant, Mormon, Unitarian, Agnostic, Atheist, Nothing in particular, other","<30K, 30K-50K, 50K-75K, 75K-100K, >= 100K, other",,Marital status,yes
Diminished Diversity-of-Thought in a Standard Large Language Model,,1,,,,,GPT-3.5,http://arxiv.org/abs/2302.07267v6,,,1,,,,,,,,,,not specified,1,,1,"male, female","Black, White, Asian, Hispanic",,,,"20, 30, ..., 70","High School, College, Advanced degree",,,"Christianity, islam, Judaism",,,,no
Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis,,1,,,,,"GPT-3.5, GPT-4",http://arxiv.org/abs/2405.07248v1,,,1,,1,,,,,,,,Great Britain,1,,,"male, female","âAsian/Asian British - Indian; Pakistani; Bangladeshiâ, âBlack/black Britishâ, âEast/south-east Asianâ, âMiddle Easternâ, âMixed race - white and Asian/Asian Britishâ, âMixed race white and black/black Britishâ, âWhiteâ",,,,integer between 18 - 99,"state, private",,,,"âUp to Â£9,999 per annum (Â£199 per week)â, âÂ£10,000 to Â£19,999 per annum (Â£200 to Â£389 per week)â, âÂ£20,000 to Â£29,999 per annum (Â£390 to Â£579 per week)â, âÂ£30,000 to Â£39,999 per annum (Â£580 to Â£769 per week)â, âÂ£40,000 to Â£49,999 per annum (Â£770 to Â£969 per week)â, âÂ£50,000 to Â£74,999 per annum (Â£970 to Â£1,449 per week)â, âÂ£75,000 or more per annum (Â£1,450 or more per week)â",,"mother's highest level of education, father's highst level of education, number of siblings, occupational status, occupational category, relationship status, number of children",no
Assessing Generalization for Subpopulation Representative Modeling via In-Context Learning,,1,,,,,GPT-3.5-turbo,http://arxiv.org/abs/2402.07368v1,,,1,,1,1,,,,,,,US Population,1,1,,"male, female","Hispanic, non-Hispanick black, non-Hispanic white",,,,"20, 35, 50, 65","bachelors degree, high school diploma, postgraduate degree, some college, but no degree","Democrat, Republican", ,1 (used only as object),"100000, 30000, 50000, 80000, >150000",,,partial
Large Language Models Still Exhibit Bias in Long Text,,,,,,,"GPT-4o, Llama-3, Mistral, Mixtral, GPT-3.5",http://arxiv.org/abs/2410.17519v2,,1,,,1,1,,,1,,,,not specified,,1,1,"man, woman","white, black, asian, latin","Indians, Chinese, Americans, Indonesians, Pakistanis, Nigerians, Brazilians, Russians, Australians, Germans",,,"young, middle, old",,"Republicans, Democrats, Liberals, Conservatives, Moderates, Socialists, Communists, Progressives, Anarchists, Nationalists","disabled, abled","Christinas, Muslims, Hindus, Buddhists, Sikhs, Spiritists, Jews, Baha'is, Jains, Shintoists, atheists, agnostics","low, high","heterosexuals; gays; lesbians; bisexuals; asexuals; pansexuals; queer, people; questioning people","body type 
have exact wording for each demographic category in appendix",yes
"""You Gotta be a Doctor, Lin"": An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations",,,,,,1,"GPT-3.5-Turbo, Llama-3-70b-Instruct",http://arxiv.org/abs/2406.12232v2,,,1,,1,1,,,,,,,US Population,,1,,"male, female with names as proxy","White, Black, Hispanic, Asian with names as proxy",,,,,,,,,,,,no
Towards Algorithmic Fidelity: Mental Health Representation across Demographics in Synthetic vs. Human-generated Data,,,,,1,,GPT-3,http://arxiv.org/abs/2403.16909v1,,1,,,1,1,,,,,,,American (implicitely),1,,,"Male, Female, Other - Women, Men","White, Black, Asian, Latinx, Other - Asian, African American, Hispanic, White",,,,,,,,,,,,partial
OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs,,1,,,,,Llama V1 7b,http://arxiv.org/abs/2309.03876v1,,1,,,1,1,,,1,,,,Reddit users,1,,,"female, male",,,"german, american, latin american, middle east",,"teenager, people over 30, old people",,"liberal, conservative",,,,,,partial
Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model,,,,,,1,"(GPT-4 for dataset creation), Llama-3.2-1B/3B-Instruct, Llama-3.1-8B-Instruct",http://arxiv.org/abs/2411.04496v1,,1,,,,,,,1,,,,,1,1,1,1,1,,1,,1,1,,,,,,"name, birthplace",yes
StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models,,,,,,,"BARD, text-davinci-003, gpt-3.5-turbo",http://arxiv.org/abs/2310.13673v2,Indira,1,1,,1,1,,,,,,,,,1,1,"Men, Women, Transgender","Asians, Black, Hispanics, Middle-Easterns, Native Americans, White","Mexicans, Arabs, Indian, German","Northerners, Southerners","Immigrants, Migrant workers","Cildren, Adults, Elderly, Teenagers, Young","Educated, Ivy Leaguers","Liberals, Conservatives, Republicans, Democrats","Blinds, Disabled","Catholics, Atheists, Christians, Buddhists, Hindu, Jews, Mulims","Poor, Lower-class, Middle-class, Rich, Upper-class, Working class",,"many more (e.g. ""sexy women"", Obese, ...)",partial
Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models,,,1,,,,"Llama 7B/65B, Llama2 13B/70B, Alpaca 7B/13B, UL2, Flan-UL2, davinci-003, gpt-3.5-turbo",http://arxiv.org/abs/2311.08472v1,,,1,,,,,,,,,,,,1,1,"1 (men, women)","1 (proxy is African-American Eglish, Standard American English)",,,,,,,,,,,,partial
Auditing the Use of Language Models to Guide Hiring Decisions,,,,,,1 (hiring),"GPT-3.5, GPT-4, Mistral-7B, Mixtral 8x7B, Claude Instant, Claude 2, Claude 3 Haiku, Claude 3 Sonnet",http://arxiv.org/abs/2404.03086v1,,,1,,1,1,,,,,,,teachers in Texas,,1,1,"men, woemn","White, Black, Hispanic",,,,,,,,,,,,no
Unveiling and Mitigating Bias in Large Language Model Recommendations: A Path to Fairness,,,,,,1,"GPT-3.5, Llama 3.1 8B",http://arxiv.org/abs/2409.10825v2,,,1,,1,1,,,,,,,,,1,1,1 (female names vs male names),"East Asia, Southeast Asia, South Asia, Western Europe, Eastern Europe, Oceania, North America, North Africa, South America, Sub-Saharan Africa (use names as proxy)",,"rural, urban",,"20, 30, 40, 50, 60",,,,,,,occupation,no
"Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models",,,,,,1,"BERT, RoBERTa, Flan-UL2, GPT-2, GPT-NeoX, OPT, Llama3 (first experiment), Claude 3 Opus, Llama 3 70B Instruct, GPT-3.5, GPT-4o (second experiment)",http://arxiv.org/abs/2407.06917v3,,1,,perplexity of pre-defined templates,1,,,,,,,,global population,,1,1,names ,names,,,,,,,,,,,,no
Improving Transfer Learning for Early Forecasting of Academic Performance by Contextualizing Language Models,,,,,,1,FLAN-T5-80M/250M/770M,https://aclanthology.org/2024.bea-1.13,Indira (done),,1,,,,,,1,,,,first-year college students in US,,1,1,1,1,,,,,,,,,1,,"academic (class standing year, major), behavioral (emotional engagement)",yes
LLM-GEm: Large Language Model-Guided Prediction of Peopleâs Empathy Levels towards Newspaper Article,,,1,,1,,GPT-3.5,https://aclanthology.org/2024.findings-eacl.147,,,1,,,,,,,,,,implicitely US population,,1,1,"male, female, others","White, Hispanic or Latino, Black or african American, Native American or American Indian, Native American or American Indian, Asian/Pacific Islander, Other",,,,1,"< high shool diploma, gigh school diploma, technical/vocational school, some college but no degree, two-year associate degree, four-year bachelor's degree, postgraduate or professional degree",,,,1,,,
Dreaming with ChatGPT: Unraveling the Challenges of LLMs Dream Generation,,,,1,,,"gpt-3.5-turbo (gpt3.5T), gpt-3.5-turbo-16k-0613 (gpt3.5T16k), gpt-3.5-turbo-0613 (gpt3.5T0613), and gpt-3.5turbo-1106 (gpt3.5T1106), gpt-4o (gpt4o)",https://aclanthology.org/2024.nlp4science-1.11,,1,,,,,,,,,,,not specified,1,,,"Female, Male","Asian, Black, White, Indian, Arab, Hispanic",,,,,,,,"Jewish, Christian, Muslim",,,,partial
Debiasing Pre-Trained Language Models via Efficient Fine-Tuning,,,,,,,GPT-2,https://aclanthology.org/2022.ltedi-1.8,,,,probability of a given sentence,,,,,1,,,,not specified,,1,1,"male, female",1,,,,,,,,1,,,profession ,yes
Deciphering Stereotypes in Pre-Trained Language Models,,,,,,,"BERT-base, RoBERTa-base, T5-small, T5-base, Flan-T5-small, Flan-T5-base",https://aclanthology.org/2023.emnlp-main.697,,,,probability of a given sentence,1,1,,,,,,1 (attention head pruning),not specified,,1,1,1,1,1,,,1,,,1,1,1,1,"profession, physical appearance",yes
SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in Generative Language Models,,,,,,,"Flan-T5-XXL, Flan-UL2",http://arxiv.org/abs/2312.07492v4,arxi v2 starts here,,1,,1,,,,,,,,US population,,1,1,Transgender,"Asian American, Latino/Latina, Multiracial, Black/African American, Middle Eastern, Native American, South Asian",,,"Documented Immigrant, Undocumented Immigrant",Old,less than highschool,,"Autism, Blind, Deaf, Mental Retardation, Schizophrenia, Speech Diasbility, Bipolar, Depression, Wheelchair (and more, see paper)","Fundamentalist Christian, Atheist, Jewish, Muslim",Working class or poor,"asexual, Lesbian/Gay/Bisexual/Non-Heterosexual","Drug use, physical appearance, illness, (and more see paper)",no
"Bias in News Summarization: Measures, Pitfalls and Corpora",,,,1,,,"BART, Pegasus, Llama-2-chat (7B, 13B and 70B)",http://arxiv.org/abs/2309.08047v3,,1,,,1,1,,,,,,,implicitely US,,1,1,"male, female","black, white (names as proxy)",,,,,,,,,,,,partial
Prebunking Elections Rumors: Artificial Intelligence Assisted Interventions Increase Confidence in American Elections,,,,,,1,Claude 3.5 Sonnet,http://arxiv.org/abs/2410.19202v1,,,1,,,1,,,,,,,US registered voters,,1,1,,,,,,,,"Democrat, Independent, Republican",,,,,,yes
Few-shot Personalization of LLMs with Mis-aligned Responses,,,,,,1,"gpt-3.5-turbo, gpt-4-turbo, LLaMA2-chat-70B",http://arxiv.org/abs/2406.18678v1,,,1,,,,,,,,,,US population and global population,,1,1,1,1,1,1,,1,1,1,,1,1,,marital status,yes
Agentic Society: Merging skeleton from real world and texture from Large Language Model,,1,,,,,glm-4,http://arxiv.org/abs/2409.10550v1,,,1,,,1,,,,,,,US population,1,,,1,1,1,1,,1,1,,,,1,,"occupation, capital gains and losses",partial
Group Robust Preference Optimization in Reward-free RLHF,,,,,,1,Gemma-2B,http://arxiv.org/abs/2405.20304v1,,,1,report loss and accuracy after training,,1,,,,,1,,global population,,1,1,,,"Nigeria, Egypt, India, China, Japan",,,,,,,,,,,yes
Revealing Fine-Grained Values and Opinions in Large Language Models,,,,,,,"Mistral, Mixtral, Zephyr, Llama 2, Llama 3, OLMo",http://arxiv.org/abs/2406.19238v2,,1,1,,1,1,,,,,,,,1,,,"male, female, non-binary",,"USA, Denmark, South Korea, Brazil, India",,,"18, 26, 48, 65, 81",,"Mainstream left, Mainstream Right, Far Left, Far Right",,,"Lower Class, Middle Class, Upper Middle Class, Upper Class",,,no
Evaluating the Experience of LGBTQ+ People Using Large Language Model Based Chatbots for Mental Health Support,,,,,,1,chatbots (not further specified),http://arxiv.org/abs/2402.09260v1,,1,,,1,,,,,,,,US residents,,1,1,"man, woman, transgender",,,1,,22-36,,,,,,"straight, gay, bisexual, lesbian",,partial
First-Person Fairness in Chatbots,,,,,,1,"GPT-3.5 turbo, GPT-4 turbo, GPT-4o mini, o1-preview, o1-mini",http://arxiv.org/abs/2410.19803v1,,1,,,1,1,,,,,,,open chatbot conversation dataset (not further specified),,1,1,"male, female (names as proxy)","Asian, Black, Hispanic, White (names as proxy)",,,,,,,,,,,,partial
The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations,,,,,,1,"ChatGPT (GPT-3.5-turbo), Llama 65B",http://arxiv.org/abs/2308.02053v2,,,1,,1,1,,,,,,,"""common"" countries selected by ChatGPT",,1,1,"Male (he/him/his) Female (she, her, hers)",,"Baseline (United States), China, India, Spain, the United Kingdom, Australia, Germany, France, Russia, Japan, Brazil, Italy, Korea, Mexico, Portugal, Ireland, the Netherlands, Switzerland, Jordan, Pakistan",,,,,,,,,,,no
"Generative Agent Simulations of 1,000 People",,1,,,,,GPT-4o,http://arxiv.org/abs/2411.10109v1,,,1,,1,1,,,,,,,US population,1,,,"female, male","white, black, Asian, other",,"urban, suburban, rural",,18 - 84,"bachelor degree, higher degree, associate's degree, high school diploma",see appendix for full list,,,see appendix for full list,see appendix for full list,,yes
"""Flex Tape Can't Fix That"": Bias and Misinformation in Edited Language Models",,,,,,,"GPT-J,Llama 2, Llama 2-chat, Mistral, Mistral-instruct",http://arxiv.org/abs/2403.00180v3,,1,1,,1,1,,,,,,1 (editing),,,1,1,"male, female","white, Black, Jewish, East Asian, Southeast Asian, North Asian, Central Asian, Latine, Indigenous, Romani, and multiracial",1,"Western Europe, Eastern Europe, North America, Caribbean, Oceania, East Asia, South Asia, Central America, Southeast Asia, North Asia, Central Asia, Middle East, Africa, and South America",,,,,,,,,"field of work, native language",no
Agent4Ranking: Semantic Robust Ranking via Personalized Query Rewriting Using Multi-agent LLM,,,,1,,1,"ChatGPT-3.5 (re-writing), BERT-based models for ranking",http://arxiv.org/abs/2312.15450v1,Friday,1,1,,1,1,,,,,,1 (Multi-gate Mixture of Experts),,,1,1,"men, women",,,,,"elderly, middle-aged, students",,,,,,,,yes
Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas,,1,,,,,GPT-4o,http://arxiv.org/abs/2406.14462v2,,1,1,,1,1,,,,,,,US population,1,,,"male, female, names","Black, White, names",,,,"older, younger, names",,"conservative, liberal",,,,,substance use,partial
What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations,,,,,,,"Llama-2, CodeLlama, Mistral, MPT-Instruct, WizardVicuna-13B, GPT-J",http://arxiv.org/abs/2311.18812v1,,,,compare embeddings,1,1,,,,,,,global population (?),,1,1,"male, female",,195 countries divided n East/West and Europe/Africa,,,,,left wing vs right wing and authoritarian vs libertarian,,Islam vs Judaism vs Christianity and reformationist vs conservative,,,career,no
JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models,,,,,,1,"GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Flash, Gemini-1.5Pro, Llama38b-Instruct,  and Llama3-70b-Instruct, Claude-3-Haiku, Claude-3-Sonnet, MistralLarge",http://arxiv.org/abs/2406.15484v2,,,1,,,1,,,,,,,job applicants,,1,1,"Male, Female",,,,,,,,,,,,,no
Fair Abstractive Summarization of Diverse Perspectives,,,,1,,,"GPT, gpt-turbo3.5, gpt-4, LLaMA, llama2-chat7/13/70B, PaLM 2, and Claude",http://arxiv.org/abs/2311.07884v2,,1,,,1,1,,,,,,,2/5 datasets implicitely US,,1,1,"male, female",,,,,,,"pro-republican, pro-democratic",,,,,sentiment,partial
Large Language Models Improve the Identification of Emergency Department Visits for Symptomatic Kidney Stones,,,,,,1,"GPT-4, GPT-3.5, Llama-2",https://doi.org/10.1101/2024.08.12.24311870,2024,1,1,,1,1,,,1,,,,patients with kidney stones in Vanderbilt Medical Center,,1,1,"males, females","White, non-White",,,,,,,,,,,,partial
"A preliminary, large-scale evaluation of the collaborative potential of human and machine creativity",,,,,,,"GPT-4.0-Turbo, Claude-3.5-Sonnet, Claude-3-Haiku, Llama-2-70b, Claude-3-Opus, GPT-3.5-Turbo, GPT-4o, and Ernie-4.0-8k",https://doi.org/10.31234/osf.io/xeh64,2024,,1,,1,1,,,,,,,,1,,1,"female, male","black, white",,,,"old, young",,,,,,,,no
GPT-3.5 altruistic advice is sensitive to reciprocal concerns but not to strategic risk,,,,,,,GPT-3.5  ,https://doi.org/10.1038/s41598-024-73306-x,2024,,1,,1,1,,,,,,,,,1,1,"female, male, non-binary",,,,,"18-30, 31-50, 51-70",,,,,,,,no
Evaluating the persuasive influence of political microtargeting with large language models,,,,,,1,GPT-4,https://doi.org/10.1073/pnas.2403116121,2024,1,,,1,1,,,,,,,"located in the US, older than 18, English as first language",,1,1,1,1,,1,,1,1,1,,1,,,occupation,partial
Socio-Demographic Biases in Medical Decision-Making by Large Language Models: A Large-Scale Multi-Model Analysis,,,,,,1,"Phi-3.5-mini, Llama-3.1, Gemma-2, Phi-3-medium, GPT-4o, Claude Sonnet 3.5, Qwen-2",https://doi.org/10.1101/2024.10.29.24316368,2024,,1,,1,1,,,,,,,U.S. population,,1,1,"transgender woman, transgender man, non-binary, male, female","Native American/Indigenous, Black, Multiracial, Hispanic/Latino, Arab, Middle-Eastern, Asian, WHite",,,,1,,,,,"Unemployed, Low-Income, Middle Income","Gay/Lesbian, Bisexual, heterosexual","Student, retired, unhoused",no
